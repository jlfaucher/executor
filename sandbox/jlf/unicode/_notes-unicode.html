<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN"
                      "http://www.w3.org/TR/html4/loose.dtd">
<html>
<head>
    <title>_notes-unicode.txt</title>
</head>
<body>
<pre>
<hr><h1 id="Accumulation_of_URLs_about_Unicode">Accumulation of URLs about Unicode</h1><hr>
Contents:
    <a href="#Unicode_standard">Unicode standard</a>
    <a href="#Unicode_general_informations">Unicode general informations</a>
    <a href="#U__notation__Unicode_escape_sequence">U+ notation, Unicode escape sequence</a>
    <a href="#Security">Security</a>
    <a href="#Segmentation__Grapheme">Segmentation, Grapheme</a>
    <a href="#Normalization__equivalence">Normalization, equivalence</a>
    <a href="#Locale">Locale</a>
    <a href="#CLDR_Common_Locale_Data_Repository">CLDR Common Locale Data Repository</a>
    <a href="#Case_mappings">Case mappings</a>
    <a href="#Collation__sorting">Collation, sorting</a>
    <a href="#Emoji">Emoji</a>
    <a href="#Countries__flags">Countries, flags</a>
    <a href="#Evidence_of_partial_or_wrong_support_of_Unicode">Evidence of partial or wrong support of Unicode</a>
    <a href="#Optimization__SIMD">Optimization, SIMD</a>
    <a href="#Variation_sequence">Variation sequence</a>
    <a href="#Whitespaces__separators">Whitespaces, separators</a>
    <a href="#Indic_languages">Indic languages</a>
    <a href="#Korean">Korean</a>
    <a href="#Japanese">Japanese</a>
    <a href="#String_Matching">String Matching</a>
    <a href="#Fuzzy_String_Matching">Fuzzy String Matching</a>
    <a href="#Levenshtein_distance_and_string_similarity">Levenshtein distance and string similarity</a>
    <a href="#String_comparison">String comparison</a>
    <a href="#Encodings">Encodings</a>
    <a href="#JSON">JSON</a>
    <a href="#TOML_serialization_format">TOML serialization format</a>
    <a href="#CBOR_Concise_Binary_Representation">CBOR Concise Binary Representation</a>
    <a href="#Binary_encoding_in_Unicode">Binary encoding in Unicode</a>
    <a href="#Invalid_format">Invalid format</a>
    <a href="#Mojibake">Mojibake</a>
    <a href="#Filenames">Filenames</a>
    <a href="#WTF8">WTF8</a>
    <a href="#Indexation_of_UTF_8_strings">Indexation of UTF-8 strings</a>
    <a href="#Rope">Rope</a>
    <a href="#ICU">ICU</a>
    <a href="#ICU_bindings">ICU bindings</a>
    <a href="#utfcpp">utfcpp</a>
    <a href="#Twitter_text_parsing">Twitter text parsing</a>
    <a href="#terminal___console">terminal / console</a>
    <a href="#Language_comparison">Language comparison</a>
    <a href="#Regular_expressions">Regular expressions</a>
    <a href="#Ada_lang">Ada lang</a>
    <a href="#C___lang__Boost">C++ lang, Boost</a>
    <a href="#DotNet__CoreFx">DotNet, CoreFx</a>
    <a href="#Dafny_lang">Dafny lang</a>
    <a href="#Factor_lang">Factor lang</a>
    <a href="#JavaScript_lang">JavaScript lang</a>
    <a href="#Julia_lang">Julia lang</a>
    <a href="#Kotlin_lang">Kotlin lang</a>
    <a href="#Lisp_lang">Lisp lang</a>
    <a href="#Mathematica_lang">Mathematica lang</a>
    <a href="#MOAR_VM_RAKU_lang">MOAR-VM RAKU lang</a>
    <a href="#Perl_lang__Perl_6_has_been_renamed_to_Raku_">Perl lang (Perl 6 has been renamed to Raku)</a>
    <a href="#PHP_lang">PHP lang</a>
    <a href="#Powershell_lang">Powershell lang</a>
    <a href="#Python_lang">Python lang</a>
    <a href="#Rexx_lang">Rexx lang</a>
    <a href="#Rust_lang">Rust lang</a>
    <a href="#Swift_lang">Swift lang</a>
    <a href="#Zig_lang__Ziglyph">Zig lang, Ziglyph</a>


<hr><h2 id="Unicode_standard">Unicode standard</h2><hr>
<a target="_blank" rel="noopener noreferrer" href="https://home.unicode.org/">https://home.unicode.org/</a>
<a target="_blank" rel="noopener noreferrer" href="https://www.unicode.org/">https://www.unicode.org/</a>                                        (same as home.unicode.org)
<a target="_blank" rel="noopener noreferrer" href="https://www.unicode.org/versions/">https://www.unicode.org/versions/</a>
<a target="_blank" rel="noopener noreferrer" href="https://www.unicode.org/versions/latest/">https://www.unicode.org/versions/latest/</a>                        (latest version)
<a target="_blank" rel="noopener noreferrer" href="https://www.unicode.org/versions/enumeratedversions.html">https://www.unicode.org/versions/enumeratedversions.html</a>        (current and previous versions)

<a target="_blank" rel="noopener noreferrer" href="https://www.unicode.org/Public/">https://www.unicode.org/Public/</a>                                 (datas for current and previous versions)

<a target="_blank" rel="noopener noreferrer" href="https://www.unicode.org/Public/MAPPINGS">https://www.unicode.org/Public/MAPPINGS</a>                         (ISO8859)
    These tables are considered to be authoritative mappings
    between the Unicode Standard and different parts of
    the ISO/IEC 8859 standard.


UNICODE COLLATION ALGORITHM
Unicode has an official string collation algorithm called UCA
<a target="_blank" rel="noopener noreferrer" href="http://unicode.org/reports/tr10/">http://unicode.org/reports/tr10/</a>
<a target="_blank" rel="noopener noreferrer" href="https://unicode.org/reports/tr10/#S2.1.1">https://unicode.org/reports/tr10/#S2.1.1</a>
The Unicode Collation Algorithm takes an input Unicode string and a Collation Element Table,
containing mapping data for characters. It produces a sort key, which is an array of
unsigned 16-bit integers. Two or more sort keys so produced can then be binary-compared
to give the correct comparison between the strings for which they were generated.


08/06/2021
Default Unicode Collation Element Table (DUCET)
For the latest version, see:
<a target="_blank" rel="noopener noreferrer" href="http://www.unicode.org/Public/UCA/latest/allkeys.txt">http://www.unicode.org/Public/UCA/latest/allkeys.txt</a>
---
UTS10-D1. Collation Weight: A non-negative integer used in the UCA to establish a means for systematic comparison of constructed sort keys.
UTS10-D2. Collation Element: An ordered list of collation weights.
UTS10-D3. Collation Level: The position of a collation weight in a collation element.


<a target="_blank" rel="noopener noreferrer" href="https://www.unicode.org/reports/tr14/">https://www.unicode.org/reports/tr14/</a>
UNICODE LINE BREAKING ALGORITHM


<a target="_blank" rel="noopener noreferrer" href="https://unicode.org/reports/tr15/#Detecting_Normalization_Forms">https://unicode.org/reports/tr15/#Detecting_Normalization_Forms</a>
UNICODE NORMALIZATION FORMS


<a target="_blank" rel="noopener noreferrer" href="http://www.unicode.org/reports/tr31/#Alternative_Identifier_Syntax">http://www.unicode.org/reports/tr31/#Alternative_Identifier_Syntax</a>


<a target="_blank" rel="noopener noreferrer" href="https://unicode.org/reports/tr36/#visual_spoofing">https://unicode.org/reports/tr36/#visual_spoofing</a>
UNICODE SECURITY CONSIDERATIONS


<a target="_blank" rel="noopener noreferrer" href="http://www.unicode.org/reports/tr39">http://www.unicode.org/reports/tr39</a>
UNICODE SECURITY MECHANISMS
<a target="_blank" rel="noopener noreferrer" href="http://www.unicode.org/Public/security/latest/confusables.txt">http://www.unicode.org/Public/security/latest/confusables.txt</a>


<a target="_blank" rel="noopener noreferrer" href="https://www.unicode.org/reports/tr51/">https://www.unicode.org/reports/tr51/</a>
Unicode  emoji


23/05/2021
<a target="_blank" rel="noopener noreferrer" href="https://www.unicode.org/notes/tn28/">https://www.unicode.org/notes/tn28/</a>
UNICODEMATH, A NEARLY PLAIN-TEXT ENCODING OF MATHEMATIC
    ùëéùëèùëê
    ùëë

    ùëé + ùëê
    ùëë

    (ùëé + ùëè)ùëõ = ‚àë (ùëõ ùëò) ùëéùëòùëèùëõ‚àíùëò


<a target="_blank" rel="noopener noreferrer" href="https://unicode.org/notes/tn5/">https://unicode.org/notes/tn5/</a>
Unicode Technical Note #5
CANONICAL EQUIVALENCE IN APPLICATIONS


03/08/2022
<a target="_blank" rel="noopener noreferrer" href="https://discourse.julialang.org/t/unicode-15-0-beta-and-sorting-collation/83090">https://discourse.julialang.org/t/unicode-15-0-beta-and-sorting-collation/83090</a>
<a target="_blank" rel="noopener noreferrer" href="https://unicode.org/emoji/charts-15.0/emoji-ordering.html">https://unicode.org/emoji/charts-15.0/emoji-ordering.html</a>


<hr><h2 id="Unicode_general_informations">Unicode general informations</h2><hr>
<a target="_blank" rel="noopener noreferrer" href="https://en.wikipedia.org/wiki/UTF-8">https://en.wikipedia.org/wiki/UTF-8</a>
<a target="_blank" rel="noopener noreferrer" href="https://en.wikipedia.org/wiki/UTF-16">https://en.wikipedia.org/wiki/UTF-16</a>
<a target="_blank" rel="noopener noreferrer" href="https://en.wikipedia.org/wiki/UTF-32">https://en.wikipedia.org/wiki/UTF-32</a>


<a target="_blank" rel="noopener noreferrer" href="http://xahlee.info/comp/unicode_index.html">http://xahlee.info/comp/unicode_index.html</a>


<a target="_blank" rel="noopener noreferrer" href="https://www.fontspace.com/unicode/analyzer">https://www.fontspace.com/unicode/analyzer</a>
<a target="_blank" rel="noopener noreferrer" href="https://www.compart.com/en/unicode/">https://www.compart.com/en/unicode/</a>


22/05/2021
<a target="_blank" rel="noopener noreferrer" href="https://onlineunicodetools.com/">https://onlineunicodetools.com/</a>
Online Unicode tools is a collection of useful browser-based utilities for manipulating Unicode text.


28/05/2021
<a target="_blank" rel="noopener noreferrer" href="https://unicode.scarfboy.com/">https://unicode.scarfboy.com/</a>
Search tool
Provides plenty of information about Unicode characters
but no encoding UTF16

<a target="_blank" rel="noopener noreferrer" href="https://unicode-table.com/en/">https://unicode-table.com/en/</a>                   search by name
Provides the encoding UTF16


<a target="_blank" rel="noopener noreferrer" href="https://www.minaret.info/test/menu.msp">https://www.minaret.info/test/menu.msp</a>
Minaret Unicode Tests
    Case Folding
    Character Type
    Collation
    Normalization
    Sorting
    Transliteration


<a target="_blank" rel="noopener noreferrer" href="https://www.gosecure.net/blog/2020/08/04/unicode-for-security-professionals/">https://www.gosecure.net/blog/2020/08/04/unicode-for-security-professionals/</a>
Unicode for Security Professionals
by Philippe Arteau | Aug 4, 2020
jlf : this article covers many of the Unicode characteristics


<a target="_blank" rel="noopener noreferrer" href="https://github.com/bits/UTF-8-Unicode-Test-Documents">https://github.com/bits/UTF-8-Unicode-Test-Documents</a>
Every Unicode character / codepoint in files and a file generator


<a target="_blank" rel="noopener noreferrer" href="http://www.ltg.ed.ac.uk/~richard/utf-8.html">http://www.ltg.ed.ac.uk/~richard/utf-8.html</a>
let convert utf8 to codepoint + symbolic name

<a target="_blank" rel="noopener noreferrer" href="https://blog.lunatech.com/posts/2009-02-03-what-every-web-developer-must-know-about-url-encoding">https://blog.lunatech.com/posts/2009-02-03-what-every-web-developer-must-know-about-url-encoding</a>

<a target="_blank" rel="noopener noreferrer" href="https://mothereff.in/utf-8">https://mothereff.in/utf-8</a>
UTF-8 encoder/decoder


<a target="_blank" rel="noopener noreferrer" href="https://corp.unicode.org/pipermail/unicode/">https://corp.unicode.org/pipermail/unicode/</a>
The Unicode Archives
January 2, 2014 - current

<a target="_blank" rel="noopener noreferrer" href="https://www.unicode.org/mail-arch/unicode-ml/">https://www.unicode.org/mail-arch/unicode-ml/</a>
March 21, 2001 - April 2, 2020

<a target="_blank" rel="noopener noreferrer" href="https://www.unicode.org/mail-arch/unicode-ml/Archives-Old/">https://www.unicode.org/mail-arch/unicode-ml/Archives-Old/</a>
October 11, 1994 - March 19, 2001

<a target="_blank" rel="noopener noreferrer" href="https://www.unicode.org/search/">https://www.unicode.org/search/</a>
Search Unicode.org


<a target="_blank" rel="noopener noreferrer" href="https://www.w3.org/TR/charmod/">https://www.w3.org/TR/charmod/</a>
Character Model for the World Wide Web 1.0: Fundamentals


<a target="_blank" rel="noopener noreferrer" href="https://www.codesections.com/blog/raku-unicode/">https://www.codesections.com/blog/raku-unicode/</a>
A deep dive into Raku's Unicode support
Grepping for "Unicode Character Database" brings us to unicode_db.c.
<a target="_blank" rel="noopener noreferrer" href="https://github.com/MoarVM/MoarVM/blob/master/src/strings/unicode_db.c">https://github.com/MoarVM/MoarVM/blob/master/src/strings/unicode_db.c</a>


<a target="_blank" rel="noopener noreferrer" href="https://www.johndcook.com/blog/2021/11/01/number-sets-html/">https://www.johndcook.com/blog/2021/11/01/number-sets-html/</a>
Number sets in HTML and Unicode
    ‚Ñï U+2115 &amp;Nopf; &amp;naturals;
    ‚Ñ§ U+2124 &amp;Zopf; &amp;integers;
    ‚Ñö U+211A &amp;Qopf; &amp;rationals;
    ‚Ñù U+211D &amp;Ropf; &amp;reals;
    ‚ÑÇ U+2102 &amp;Copf; &amp;complexes;
    ‚Ñç U+210D &amp;Hopf; &amp;quaternions;


<a target="_blank" rel="noopener noreferrer" href="https://gregtatum.com/writing/2021/encoding-text-utf-32-utf-16-unicode/">https://gregtatum.com/writing/2021/encoding-text-utf-32-utf-16-unicode/</a>
<a target="_blank" rel="noopener noreferrer" href="https://gregtatum.com/writing/2021/encoding-text-utf-8-unicode/">https://gregtatum.com/writing/2021/encoding-text-utf-8-unicode/</a>


<a target="_blank" rel="noopener noreferrer" href="https://lwn.net/Articles/667669/">https://lwn.net/Articles/667669/</a>
Is the current Unicode design impractical?


<a target="_blank" rel="noopener noreferrer" href="https://www.sciencedirect.com/science/article/pii/S1742287613000595">https://www.sciencedirect.com/science/article/pii/S1742287613000595</a>
Unicode search of dirty data.
This paper discusses problems arising in digital forensics with regard to Unicode,
character encodings, and search. It describes how multipattern search can handle
the different text encodings encountered in digital forensics and a number of issues
pertaining to proper handling of Unicode in search patterns. Finally, we demonstrate
the feasibility of the approach and discuss the integration of our developed search
engine, lightgrep, with the popular bulk_extractor tool.
---
There are UTF-16LE strings which contain completely different UTF-8 strings as prefixes.
For example the byte sequence which is ‚Äúnonsense‚Äù in UTF-8 is ÊΩÆÁçÆÊπ•Êï≥ in UTF-16LE (!)
    "nonsense"~c2x=                         -- '6E6F6E73656E7365'
    "nonsense"~text("utf16be")~c2x=         -- '6E6F 6E73 656E 7365'
    "nonsense"~text("utf16be")~c2u=         -- 'U+6E6F U+6E73 U+656E U+7365'
    "nonsense"~text("utf16be")~utf8=        -- T'ÊπØÊπ≥ÊïÆÁç•'      Le potage
    "nonsense"~text("utf16le")~c2x=         -- '6E6F 6E73 656E 7365'
    "nonsense"~text("utf16le")~c2u=         -- 'U+6F6E U+736E U+6E65 U+6573'
    "nonsense"~text("utf16le")~utf8=        -- T'ÊΩÆÁçÆÊπ•Êï≥'      mar√©e


<a target="_blank" rel="noopener noreferrer" href="https://github.com/simsong/bulk_extractor">https://github.com/simsong/bulk_extractor</a>


<hr><h2 id="U__notation__Unicode_escape_sequence">U+ notation, Unicode escape sequence</h2><hr>
29/05/2021
<a target="_blank" rel="noopener noreferrer" href="https://stackoverflow.com/questions/1273693/why-is-u-used-to-designate-a-unicode-code-point/8891355">https://stackoverflow.com/questions/1273693/why-is-u-used-to-designate-a-unicode-code-point/8891355</a>
The Python language defines the following string literals:
    u'xyz' to indicate a Unicode string, a sequence of Unicode characters
    '\uxxxx' to indicate a string with a unicode character denoted by four hex digits
    '\Uxxxxxxxx' to indicate a string with a unicode character denoted by eight hex digits
    \N{name}    Character named name in the Unicode database
    \uxxxx      Character with 16-bit hex value xxxx. Exactly four hex digits are required.
    \Uxxxxxxxx  Character with 32-bit hex value xxxxxxxx. Exactly eight hex digits are required.


<a target="_blank" rel="noopener noreferrer" href="https://www.perl.com/article/json-unicode-and-perl-oh-my-/">https://www.perl.com/article/json-unicode-and-perl-oh-my-/</a>
Its \uXXXX escapes support only characters within Unicode‚Äôs BMP;
to store emoji or other non-BMP characters you either have to encode to UTF-8 directly.
or indicate a UTF-16 surrogate pair in \uXXXX escapes.


<a target="_blank" rel="noopener noreferrer" href="https://corp.unicode.org/pipermail/unicode/2021-April/009410.html">https://corp.unicode.org/pipermail/unicode/2021-April/009410.html</a>
Need reference to good ABNF for \uXXXX syntax


<a target="_blank" rel="noopener noreferrer" href="https://bit.ly/UnicodeEscapeSequences">https://bit.ly/UnicodeEscapeSequences</a>
Unicode Escape Sequences Across Various Languages and Platforms


<hr><h2 id="Security">Security</h2><hr>
<a target="_blank" rel="noopener noreferrer" href="https://www.trojansource.codes/">https://www.trojansource.codes/</a>

<a target="_blank" rel="noopener noreferrer" href="https://api.mtr.pub/vhf/confusable_homoglyphs">https://api.mtr.pub/vhf/confusable_homoglyphs</a>


<hr><h2 id="Segmentation__Grapheme">Segmentation, Grapheme</h2><hr>
29/05/2021
<a target="_blank" rel="noopener noreferrer" href="https://github.com/alvinlindstam/grapheme">https://github.com/alvinlindstam/grapheme</a>
<a target="_blank" rel="noopener noreferrer" href="https://pypi.org/project/grapheme/">https://pypi.org/project/grapheme/</a>
Here too, he says that CR+LF is a grapheme...

Same here:
<a target="_blank" rel="noopener noreferrer" href="https://www.reddit.com/r/programming/comments/m274cg/til_rn_crlf_is_a_single_grapheme_cluster/">https://www.reddit.com/r/programming/comments/m274cg/til_rn_crlf_is_a_single_grapheme_cluster/</a>
<a target="_blank" rel="noopener noreferrer" href="https://unicode.org/reports/tr29/#Table_Combining_Char_Sequences_and_Grapheme_Clusters">https://unicode.org/reports/tr29/#Table_Combining_Char_Sequences_and_Grapheme_Clusters</a>


01/06/2021
<a target="_blank" rel="noopener noreferrer" href="https://halt.software/optimizing-unicodes-grapheme-cluster-break-algorithm/">https://halt.software/optimizing-unicodes-grapheme-cluster-break-algorithm/</a>
They claim this improvement:
For the simple data set, this was 0.38 of utf8proc time.
For the complex data set, this was 0.56 of utf8proc time.


01/06/2021
<a target="_blank" rel="noopener noreferrer" href="https://docs.rs/unicode-segmentation/1.7.1/unicode_segmentation/">https://docs.rs/unicode-segmentation/1.7.1/unicode_segmentation/</a>
GraphemeCursor	Cursor-based segmenter for grapheme clusters.
GraphemeIndices	External iterator for grapheme clusters and byte offsets.
Graphemes	External iterator for a string's grapheme clusters.
USentenceBoundIndices	External iterator for sentence boundaries and byte offsets.
USentenceBounds	External iterator for a string's sentence boundaries.
UWordBoundIndices	External iterator for word boundaries and byte offsets.
UWordBounds	External iterator for a string's word boundaries.
UnicodeSentences	An iterator over the substrings of a string which, after splitting the string on sentence boundaries, contain any characters with the Alphabetic property, or with General_Category=Number.
UnicodeWords	An iterator over the substrings of a string which, after splitting the string on word boundaries, contain any characters with the Alphabetic property, or with General_Category=Number.


<a target="_blank" rel="noopener noreferrer" href="https://github.com/knighton/unicode">https://github.com/knighton/unicode</a>
Minimalist Unicode normalization/segmentation library. Python and C++.
Abandonned, last commit 21/05/2015


07/06/2021
<a target="_blank" rel="noopener noreferrer" href="https://news.ycombinator.com/item?id=20914184">https://news.ycombinator.com/item?id=20914184</a>
String lengths in Unicode
    Claude Roux
    We went through a lot of pain to get this right in Tamgu ( <a target="_blank" rel="noopener noreferrer" href="https://github.com/naver/tamgu">https://github.com/naver/tamgu</a> ).
    In particular, emojis can be encoded across 5 or 6 Unicode characters.
    A "black thumb up" is encoded with 2 Unicode characters: the thumb glyph and its color.
    This comes at a cost. Every time you extract a sub-string from a string,
    you have to scan it first for its codepoints, then convert character positions
    into byte positions. One way to speed up stuff a bit, is to check if the string
    is in ASCII (see <a target="_blank" rel="noopener noreferrer" href="https://lemire.me/blog/2018/05/16/validating-utf-8-strings-u">https://lemire.me/blog/2018/05/16/validating-utf-8-strings-u</a> )
    and apply regular operator then.
    We implemented many techniques based on "intrinsics" instructions to speed up
    conversions and search in order to avoid scanning for codepoints.
    See <a target="_blank" rel="noopener noreferrer" href="https://github.com/naver/tamgu/blob/master/src/conversion.cxx">https://github.com/naver/tamgu/blob/master/src/conversion.cxx</a> for more information.
    <a target="_blank" rel="noopener noreferrer" href="https://github.com/naver/tamgu/wiki/4.-Speed-up-UTF8-string-processing-with-Intel's-%22intrinsics%22-instructions-(en)">https://github.com/naver/tamgu/wiki/4.-Speed-up-UTF8-string-processing-with-Intel's-%22intrinsics%22-instructions-(en)</a>
jlf: they have specific support for Korean... Probably because the NAVER company is from Republic of Korea ?
08/06/2021
<a target="_blank" rel="noopener noreferrer" href="https://twitter.com/hashtag/tamgu?src=hashtag_click">https://twitter.com/hashtag/tamgu?src=hashtag_click</a>
<a target="_blank" rel="noopener noreferrer" href="https://twitter.com/hashtag/TAL?src=hashtag_click">https://twitter.com/hashtag/TAL?src=hashtag_click</a>
#tamgu le #langage_de_programmation pour le Traitement Automatique des Langues (#TAL).


jlf 30/09/2021
I have a doubt about that:
Is üë©‚Äçüë®‚Äçüë©‚Äçüëß' really a grapheme?
When moving the cursor in BBEdit, I see a boundary between each character.
[later]
Ok, when moving the cursor in Visual Studio Code, it's really a unique grapheme, no way to put the cursor "inside".
And the display is aligned with what I see in Google Chrome : one WOMAN followed by a family, and no way to put the cursor between the WOMAN and the family.
---
<a target="_blank" rel="noopener noreferrer" href="https://www.unicode.org/review/pr-27.html">https://www.unicode.org/review/pr-27.html</a>       (old, talk about Unicode 4)
<a target="_blank" rel="noopener noreferrer" href="https://www.unicode.org/reports/tr29/#Grapheme_Cluster_Boundaries">https://www.unicode.org/reports/tr29/#Grapheme_Cluster_Boundaries</a>   (todo: review occurences of ZWJ)


29/10/2021
<a target="_blank" rel="noopener noreferrer" href="https://h3manth.com/posts/unicode-segmentation-in-javascript/">https://h3manth.com/posts/unicode-segmentation-in-javascript/</a>
<a target="_blank" rel="noopener noreferrer" href="https://github.com/tc39/proposal-intl-segmenter">https://github.com/tc39/proposal-intl-segmenter</a>


<a target="_blank" rel="noopener noreferrer" href="https://news.ycombinator.com/item?id=21690326">https://news.ycombinator.com/item?id=21690326</a>
Tailored grapheme clusters
Grapheme clusters are locale-dependent, much like string collation is locale-dependent.
What Unicode gives you by default, the (extended) grapheme cluster, is as useful as
the DUCET (Default Unicode Collation Element Table); while you can live with them,
you would be unsatisfied. In fact there are tons of Unicode bugs that can't be corrected
due to the compatibility reason, and can only be fixed via tailored locale-dependent schemes.


<hr><h2 id="Normalization__equivalence">Normalization, equivalence</h2><hr>
26/11/2013
Text normalization in Go
<a target="_blank" rel="noopener noreferrer" href="https://blog.golang.org/normalization">https://blog.golang.org/normalization</a>


27/11/2013
The string type is broken
<a target="_blank" rel="noopener noreferrer" href="https://mortoray.com/2013/11/27/the-string-type-is-broken/">https://mortoray.com/2013/11/27/the-string-type-is-broken/</a>
In the comments
Objective-C‚Äôs NSString type does correctly upper-case baÔ¨Ñe into BAFFLE.
(where the rectangle is a grapheme showing 2 small 'f')
Q: What about getting the first three characters of ‚ÄúbaÔ¨Ñe‚Äù? Is ‚Äúbaf‚Äù the correct answer?
A:  That‚Äôs a good question. I suspect ‚Äúbaf‚Äù is the correct answer, and I wonder if there is any library that does it.
    I suspect if you normalize it first (since the ffl would disappear I think).
A:  The ligarture disappears in NFK[CD] but not in NF[CD].
    Whether normalization to NFK[CD] is a good idea depends (as always) on the situation.
    For visual grapheme cluster counting, one would convert the entire text to NFKC.
    For getting teaser text from an article i would not a normalization step
    and let a ligature count as just one grapheme cluster even if it may resemble three of them logically.
    I assume, that articles are stored in NFC (the nondestructive normalization form with smallest memory footprint).
    The Unicode standard does not treat ligatures as containing more than one grapheme cluster for that normalization forms that permits them.
    So ‚ÄúeÔ¨Ñab‚Äù (jlf: efflab) is the correct result of reversing ‚ÄúbaÔ¨Ñe‚Äù (jlf: baffle)
    and ‚ÄúbaÔ¨Ñe‚Äù[2] has to return ‚ÄúÔ¨Ñ‚Äù even when working on the grapheme cluster level!

    There may or may not be a need for another grapheme cluster definition that permits splitting of ligatures in NF[CD].
    A straight forward way to implement a reverse function adhering to that special definition would NFKC each Unicode grapheme cluster on the fly.
    When that results in multiple Unicode grapheme clusters, that are used ‚Äì else the original is preserved (so that ‚Äú‚Ñï‚Äù does not become ‚ÄúN‚Äù).
    The real problem is to find a good name for that special interpretation of a grapheme cluster‚Ä¶
Note :
    see also the comment of Tom Christiansen about casing.
    I don't copy-paste here, too long.


<a target="_blank" rel="noopener noreferrer" href="https://github.com/blackwinter/unicode">https://github.com/blackwinter/unicode</a>
Unicode normalization library. (Mirror of Yoshida-san's code base to maintain the RubyGem.)
Abandonned, last commit 07/07/2016


<a target="_blank" rel="noopener noreferrer" href="https://github.com/sjorek/unicode-normalization">https://github.com/sjorek/unicode-normalization</a>
An enhanced facade to existing unicode-normalization implementations
Last commit 25/03/2018


<a target="_blank" rel="noopener noreferrer" href="https://docs.microsoft.com/en-us/windows/win32/intl/using-unicode-normalization-to-represent-strings">https://docs.microsoft.com/en-us/windows/win32/intl/using-unicode-normalization-to-represent-strings</a>
Using Unicode Normalization to Represent Strings


<a target="_blank" rel="noopener noreferrer" href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/String/normalize">https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/String/normalize</a>
String.prototype.normalize()
The normalize() method returns the Unicode Normalization Form of the string.


<a target="_blank" rel="noopener noreferrer" href="https://forums.swift.org/t/string-case-folding-and-normalization-apis/14663/3">https://forums.swift.org/t/string-case-folding-and-normalization-apis/14663/3</a>
For the comments


<a target="_blank" rel="noopener noreferrer" href="https://en.wikipedia.org/wiki/Unicode_equivalence">https://en.wikipedia.org/wiki/Unicode_equivalence</a>
Unicode equivalence is the specification by the Unicode character encoding standard that some sequences
of code points represent essentially the same character. This feature was introduced in the standard
to allow compatibility with preexisting standard character sets, which often included similar or identical characters.


On Wed, Oct 28, 2020 at 9:54 AM Mark Davis ‚òïÔ∏è &lt;mark@macchiato.com&gt; wrote:
Re: [icu-support] Options for Immutable Collation?

        I think your search for 'middle ground' is fruitless.
            An NFKD ordering is not correct for any human language, and changes with each new Unicode version.
            And even the default Unicode collation ordering is wrong for many languages, because there is no order that simultaneously satisfies all (eg German ordering and Swedish ordering are incompatible).
        Your 'middle ground' would be correct for nobody, and yet be unstable across Unicode versions; or worse yet, fail for new characters.

        IMO, the best practice for a file system (or like systems) is to store in codepoint order. When called upon to present a sorted list of files to a user, the displaying program should sort that list according to the user's language preferences.

    You are right: for a deterministic/reproducible list sorting for a cross-platform filesystem API, anything more complex would be an implementation hazard.

    However, after reviewing both developer discussions and implementation of Unicode handling in 6+ filesystems, IDNA200X, PRECIS and getting roped into work on an IETF i18n filesystem best-practices RFC ... I've got some thoughts.  Thoughts that I will put into a new thread after I do some experimenting : ).

    Thank you all so much!!!
    -Zach Lym


08/06/2021
<a target="_blank" rel="noopener noreferrer" href="https://fr.wikipedia.org/wiki/Normalisation_Unicode">https://fr.wikipedia.org/wiki/Normalisation_Unicode</a>
NFD     Les caract√®res sont d√©compos√©s par √©quivalence canonique et r√©ordonn√©s
        canonical decomposition
NFC     Les caract√®res sont d√©compos√©s par √©quivalence canonique, r√©ordonn√©s, et compos√©s par √©quivalence canonique
        canonical decomposition followed by canonical composition
NFKD    Les caract√®res sont d√©compos√©s par √©quivalence canonique et de compatibilit√©, et sont r√©ordonn√©s
        compatibility decomposition
NFKC    Les caract√®res sont d√©compos√©s par √©quivalence canonique et de compatibilit√©, sont r√©ordonn√©s et sont compos√©s par √©quivalence canonique
        compatibility decomposition followed by canonical composition
FCD     "Fast C or D" form; cf. UTN #5
FCC     "Fast C Contiguous"; cf. UTN #5


09/06/2021
Rust
<a target="_blank" rel="noopener noreferrer" href="https://docs.rs/unicode-normalization">https://docs.rs/unicode-normalization</a>
    Decompositions  External iterator for a string decomposition‚Äôs characters.
    Recompositions  External iterator for a string recomposition‚Äôs characters.
    Replacements    External iterator for replacements for a string‚Äôs characters.
    StreamSafe      UAX15-D4: This iterator keeps track of how many non-starters
                    there have been since the last starter in NFKD and will emit
                    a Combining Grapheme Joiner (U+034F) if the count exceeds 30.

    is_nfc                      Authoritatively check if a string is in NFC.
    is_nfc_quick                Quickly check if a string is in NFC, potentially returning IsNormalized::Maybe if further checks are necessary. In this case a check like s.chars().nfc().eq(s.chars()) should suffice.
    is_nfc_stream_safe          Authoritatively check if a string is Stream-Safe NFC.
    is_nfc_stream_safe_quick    Quickly check if a string is Stream-Safe NFC.
    is_nfd                      Authoritatively check if a string is in NFD.
    is_nfd_quick                Quickly check if a string is in NFD.
    is_nfd_stream_safe          Authoritatively check if a string is Stream-Safe NFD.
    is_nfd_stream_safe_quick    Quickly check if a string is Stream-Safe NFD.
    is_nfkc                     Authoritatively check if a string is in NFKC.
    is_nfkc_quick               Quickly check if a string is in NFKC.
    is_nfkd                     Authoritatively check if a string is in NFKD.
    is_nfkd_quick               Quickly check if a string is in NFKD.

    Enums
    IsNormalized	The QuickCheck algorithm can quickly determine if a text is or isn‚Äôt normalized without any allocations in many cases, but it has to be able to return Maybe when a full decomposition and recomposition is necessary.


08/06/2021
Pharo
<a target="_blank" rel="noopener noreferrer" href="https://medium.com/concerning-pharo/an-implementation-of-unicode-normalization-7c6719068f43">https://medium.com/concerning-pharo/an-implementation-of-unicode-normalization-7c6719068f43</a>


<a target="_blank" rel="noopener noreferrer" href="https://github.com/duerst/eprun">https://github.com/duerst/eprun</a>
Efficient Pure Ruby Unicode Normalization (eprun)
According to julia/utf8proc, the interesting part is the tests.


<a target="_blank" rel="noopener noreferrer" href="https://corp.unicode.org/pipermail/unicode/2020-December/009150.html">https://corp.unicode.org/pipermail/unicode/2020-December/009150.html</a>
Normalization Generics (NFx, NFKx, NFxy)


<a target="_blank" rel="noopener noreferrer" href="https://6guts.wordpress.com/2015/04/12/this-week-unicode-normalization-many-rts/">https://6guts.wordpress.com/2015/04/12/this-week-unicode-normalization-many-rts/</a>


<a target="_blank" rel="noopener noreferrer" href="https://gregtatum.com/writing/2021/diacritical-marks/">https://gregtatum.com/writing/2021/diacritical-marks/</a>
DIACRITICAL MARKS IN UNICODE


<a target="_blank" rel="noopener noreferrer" href="https://news.ycombinator.com/item?id=29751641">https://news.ycombinator.com/item?id=29751641</a>
Unicode Normalization Forms: When √∂ ‚â† √∂
<a target="_blank" rel="noopener noreferrer" href="https://blog.opencore.ch/posts/unicode-normalization-forms/">https://blog.opencore.ch/posts/unicode-normalization-forms/</a>


<hr><h2 id="Locale">Locale</h2><hr>
02/06/2021
<a target="_blank" rel="noopener noreferrer" href="https://www.php.net/manual/fr/function.setlocale.php">https://www.php.net/manual/fr/function.setlocale.php</a>
Warning
The locale information is maintained per process, not per thread.
If you are running PHP on a multithreaded server API , you may experience sudden changes
in locale settings while a script is running, though the script itself never called setlocale().
This happens due to other scripts running in different threads of the same process at the same time,
changing the process-wide locale using setlocale().
On Windows, locale information is maintained per thread as of PHP 7.0.5.
On Windows, setlocale(LC_ALL, '') sets the locale names from the system's regional/language settings (accessible via Control Panel).


<hr><h2 id="CLDR_Common_Locale_Data_Repository">CLDR Common Locale Data Repository</h2><hr>
19/06/2021
<a target="_blank" rel="noopener noreferrer" href="https://github.com/twitter/twitter-cldr-rb">https://github.com/twitter/twitter-cldr-rb</a>
Ruby implementation of the ICU (International Components for Unicode) that uses
the Common Locale Data Repository to format dates, plurals, and more.


<a target="_blank" rel="noopener noreferrer" href="https://github.com/twitter/twitter-cldr-js">https://github.com/twitter/twitter-cldr-js</a>
JavaScript implementation of the ICU (International Components for Unicode) that uses
the Common Locale Data Repository to format dates, plurals, and more. Based on twitter-cldr-rb.


<hr><h2 id="Case_mappings">Case mappings</h2><hr>
<a target="_blank" rel="noopener noreferrer" href="https://unicode.org/faq/casemap_charprop.html">https://unicode.org/faq/casemap_charprop.html</a>


<a target="_blank" rel="noopener noreferrer" href="https://stackoverflow.com/questions/7360996/unicode-correct-title-case-in-java?noredirect=1&lq=1">https://stackoverflow.com/questions/7360996/unicode-correct-title-case-in-java?noredirect=1&lq=1</a>
Unicode-correct title case in Java


<a target="_blank" rel="noopener noreferrer" href="https://docs.rs/unicode-case-mapping/latest/unicode_case_mapping/">https://docs.rs/unicode-case-mapping/latest/unicode_case_mapping/</a>
Example
assert_eq!(unicode_case_mapping::to_lowercase('ƒ∞'), ['i' as u32, 0x0307]);
assert_eq!(unicode_case_mapping::to_lowercase('√ü'), ['√ü' as u32, 0]);
assert_eq!(unicode_case_mapping::to_uppercase('√ü'), ['S' as u32, 'S' as u32, 0]);
assert_eq!(unicode_case_mapping::to_titlecase('√ü'), ['S' as u32, 's' as u32, 0]);
assert_eq!(unicode_case_mapping::to_titlecase('-'), [0; 3]);
assert_eq!(unicode_case_mapping::case_folded('I'), NonZeroU32::new('i' as u32));
assert_eq!(unicode_case_mapping::case_folded('√ü'), None);
assert_eq!(unicode_case_mapping::case_folded('·∫û'), NonZeroU32::new('√ü' as u32));


<a target="_blank" rel="noopener noreferrer" href="https://kotlinlang.org/api/latest/jvm/stdlib/kotlin.text/titlecase.html">https://kotlinlang.org/api/latest/jvm/stdlib/kotlin.text/titlecase.html</a>
fun Char.titlecase(): String
    val chars = listOf('a', '«Ö', '≈â', '+', '√ü')
    val titlecaseChar = chars.map { it.titlecaseChar() }
    val titlecase = chars.map { it.titlecase() }
    println(titlecaseChar) // [A, «Ö, ≈â, +, √ü]
    println(titlecase) // [A, «Ö,  ºN, +, Ss]
fun Char.titlecase(locale: Locale): String
    val chars = listOf('a', '«Ö', '≈â', '+', '√ü', 'i')
    val titlecase = chars.map { it.titlecase() }
    val turkishLocale = Locale.forLanguageTag("tr")
    val titlecaseTurkish = chars.map { it.titlecase(turkishLocale) }
    println(titlecase) // [A, «Ö,  ºN, +, Ss, I]
    println(titlecaseTurkish) // [A, «Ö,  ºN, +, Ss, ƒ∞]


<hr><h2 id="Collation__sorting">Collation, sorting</h2><hr>
01/06/2021
<a target="_blank" rel="noopener noreferrer" href="https://github.com/jgm/unicode-collation">https://github.com/jgm/unicode-collation</a>
<a target="_blank" rel="noopener noreferrer" href="https://hackage.haskell.org/package/unicode-collation">https://hackage.haskell.org/package/unicode-collation</a>
Haskell implementation of the Unicode Collation Algorithm


<a target="_blank" rel="noopener noreferrer" href="https://icu4c-demos.unicode.org/icu-bin/collation.html">https://icu4c-demos.unicode.org/icu-bin/collation.html</a>
ICU Collation Demo


<a target="_blank" rel="noopener noreferrer" href="https://www.enterprisedb.com/docs/epas/latest/epas_guide/03_database_administration/06_unicode_collation_algorithm/">https://www.enterprisedb.com/docs/epas/latest/epas_guide/03_database_administration/06_unicode_collation_algorithm/</a>
Unicode Collation Algorithm


<a target="_blank" rel="noopener noreferrer" href="https://www.minaret.info/test/collate.msp">https://www.minaret.info/test/collate.msp</a>
This page provides a means to convert a string of Unicode characters into a binary collation key using
the Java language version ("icu4j") of the IBM International Components for Unicode (ICU) library.
A collation key is the basis for sorting and comparing strings in a language-sensitive Unicode environment.
A collation key is built using a "locale" (a designation for a particular laguage or a variant) and a comparison level.
The levels supported here (Primary, Secondary, Tertiary, Quaternary and Identical) correspond to levels
"L1" through "Ln" as described in Unicode Technical Standard #10 - Unicode Collation Algorithm.
When comparing collation keys for two different strings, both keys must have been created using the same locale
and comparison level in order to be meaningful. The two keys are compared from left to right, byte for byte
until one of the bytes is not equal to the other. Whichever byte is numerically less than the other causes
the source string for that collation key to sort before the other string.


<a target="_blank" rel="noopener noreferrer" href="https://lemire.me/blog/2018/12/17/sorting-strings-properly-is-stupidly-hard/">https://lemire.me/blog/2018/12/17/sorting-strings-properly-is-stupidly-hard/</a>
It's the comments section which is interesting.


<a target="_blank" rel="noopener noreferrer" href="https://discourse.julialang.org/t/sorting-strings-by-unicode-collation-order/11195">https://discourse.julialang.org/t/sorting-strings-by-unicode-collation-order/11195</a>
Not supported


<a target="_blank" rel="noopener noreferrer" href="https://en.wikipedia.org/wiki/Natural_sort_order">https://en.wikipedia.org/wiki/Natural_sort_order</a>
Natural sort order is an ordering of strings in alphabetical order,
except that multi-digit numbers are ordered as a single character.
Natural sort order has been promoted as being more human-friendly ("natural")
than the machine-oriented pure alphabetical order.
For example, in alphabetical sorting "z11" would be sorted before "z2"
because "1" is sorted as smaller than "2",
while in natural sorting "z2" is sorted before "z11" because "2" is sorted as smaller than "11".
Alphabetical sorting:
    z11
    z2
Natural sorting:
    z2
    z11
Functionality to sort by natural sort order is built into many programming languages and libraries.


02/06/2021
<a target="_blank" rel="noopener noreferrer" href="https://www.postgresql.org/message-id/flat/BA6132ED-1F6B-4A0B-AC22-81278F5AB81E%40tripadvisor.com">https://www.postgresql.org/message-id/flat/BA6132ED-1F6B-4A0B-AC22-81278F5AB81E%40tripadvisor.com</a>
The dangers of streaming across versions of glibc: A cautionary tale
SELECT 'Ôº≠' &gt; '‡Æê';
'FULLWIDTH LATIN CAPITAL LETTER M' (U+FF2D)
'TAMIL LETTER AI' (U+0B90)
Across different machines, running the same version of postgres, and in databases
with identical character encodings and collations ('en_US.UTF-8') that select will
return different results if the version of glibc is different.
master:src/backend/utils/adt/varlena.c:1494,1497  These are the lines where postgres
calls strcoll_l and strcoll, in order to sort strings in a locale aware manner.
The reality is that there are different versions of glibc out there in the wild,
and they do not sort consistently across versions/environments.


<a target="_blank" rel="noopener noreferrer" href="https://collations.info/concepts/">https://collations.info/concepts/</a>
a site devoted to working with Collations, Unicode, Encodings, Code Pages, etc in Microsoft SQL Server.


<hr><h2 id="Emoji">Emoji</h2><hr>
<a target="_blank" rel="noopener noreferrer" href="https://www.unicode.org/Public/emoji/15.0/emoji-test.txt">https://www.unicode.org/Public/emoji/15.0/emoji-test.txt</a>


<a target="_blank" rel="noopener noreferrer" href="https://emojipedia.org/">https://emojipedia.org/</a>


<a target="_blank" rel="noopener noreferrer" href="http://xahlee.info/comp/unicode_emoticons.html">http://xahlee.info/comp/unicode_emoticons.html</a>


29/05/2021
<a target="_blank" rel="noopener noreferrer" href="https://tonsky.me/blog/emoji/">https://tonsky.me/blog/emoji/</a>


<hr><h2 id="Countries__flags">Countries, flags</h2><hr>
22/05/2021
<a target="_blank" rel="noopener noreferrer" href="https://en.wikipedia.org/wiki/Regional_indicator_symbol">https://en.wikipedia.org/wiki/Regional_indicator_symbol</a>
Regional indicator symbol


<a target="_blank" rel="noopener noreferrer" href="https://en.wikipedia.org/wiki/ISO_3166-1">https://en.wikipedia.org/wiki/ISO_3166-1</a>
ISO 3166-1 (Codes for the representation of names of countries and their subdivisions)


<a target="_blank" rel="noopener noreferrer" href="https://observablehq.com/@jobleonard/which-unicode-flags-are-reversible">https://observablehq.com/@jobleonard/which-unicode-flags-are-reversible</a>


<hr><h2 id="Evidence_of_partial_or_wrong_support_of_Unicode">Evidence of partial or wrong support of Unicode</h2><hr>
13/08/2013
We don‚Äôt need a string type
<a target="_blank" rel="noopener noreferrer" href="https://mortoray.com/2013/08/13/we-dont-need-a-string-type/">https://mortoray.com/2013/08/13/we-dont-need-a-string-type/</a>


01/12/2013
Strings in Ruby are UTF-8 now‚Ä¶ right?
<a target="_blank" rel="noopener noreferrer" href="http://andre.arko.net/2013/12/01/strings-in-ruby-are-utf-8-now/">http://andre.arko.net/2013/12/01/strings-in-ruby-are-utf-8-now/</a>


14/07/2017
Testing Ruby's Unicode Support
<a target="_blank" rel="noopener noreferrer" href="http://blog.honeybadger.io/ruby-s-unicode-support/">http://blog.honeybadger.io/ruby-s-unicode-support/</a>


22/05/2021
Emoji.length == 2
<a target="_blank" rel="noopener noreferrer" href="https://news.ycombinator.com/item?id=13830177">https://news.ycombinator.com/item?id=13830177</a>
Lot of comments, did not read all, to continue


22/05/2021
<a target="_blank" rel="noopener noreferrer" href="https://manishearth.github.io/blog/2017/01/14/stop-ascribing-meaning-to-unicode-code-points/">https://manishearth.github.io/blog/2017/01/14/stop-ascribing-meaning-to-unicode-code-points/</a>
Let's Stop Ascribing Meaning to Code Points


18/07/2021
<a target="_blank" rel="noopener noreferrer" href="https://manishearth.github.io/blog/2017/01/15/breaking-our-latin-1-assumptions/">https://manishearth.github.io/blog/2017/01/15/breaking-our-latin-1-assumptions/</a>
Breaking Our Latin-1 Assumptions


<hr><h2 id="Optimization__SIMD">Optimization, SIMD</h2><hr>
08/06/2021
<a target="_blank" rel="noopener noreferrer" href="https://lemire.me/blog/2018/05/16/validating-utf-8-strings-using-as-little-as-0-7-cycles-per-byte/">https://lemire.me/blog/2018/05/16/validating-utf-8-strings-using-as-little-as-0-7-cycles-per-byte/</a>


<a target="_blank" rel="noopener noreferrer" href="https://github.com/lemire/fastvalidate-utf-8">https://github.com/lemire/fastvalidate-utf-8</a>
header-only library to validate utf-8 strings at high speeds (using SIMD instructions)


08/06/2021
<a target="_blank" rel="noopener noreferrer" href="https://github.com/simdjson/simdjson">https://github.com/simdjson/simdjson</a>
simdjson : Parsing gigabytes of JSON per second
The simdjson library uses commonly available SIMD instructions and microparallel algorithms
to parse JSON 4x faster than RapidJSON and 25x faster than JSON for Modern C++.
Minify JSON at 6 GB/s, validate UTF-8 at 13 GB/s, NDJSON at 3.5 GB/s


<a target="_blank" rel="noopener noreferrer" href="https://arxiv.org/abs/2010.03090">https://arxiv.org/abs/2010.03090</a>
Validating UTF-8 In Less Than One Instruction Per Byte
John Keiser, Daniel Lemire
The majority of text is stored in UTF-8, which must be validated on ingestion.
We present the lookup algorithm, which outperforms UTF-8 validation routines used
in many libraries and languages by more than 10 times using commonly available SIMD instructions.
To ensure reproducibility, our work is freely available as open source software.


<a target="_blank" rel="noopener noreferrer" href="https://r-libre.teluq.ca/2178/">https://r-libre.teluq.ca/2178/</a>
    Recherche et analyse de solutions performantes pour le traitement de fichiers JSON dans un langage de haut niveau [r-libre/2178]
Referenced from
    <a target="_blank" rel="noopener noreferrer" href="https://lemire.me/blog/">https://lemire.me/blog/</a>
    Daniel Lemire's blog ‚Äì Daniel Lemire is a computer science professor at the University of Quebec (TELUQ) in Montreal.
    His research is focused on software performance and data engineering. He is a techno-optimist.


<hr><h2 id="Variation_sequence">Variation sequence</h2><hr>
22/05/2021
List of all code points that can display differently via a variation sequence
<a target="_blank" rel="noopener noreferrer" href="http://randomguy32.de/unicode/charts/standardized-variants/#emoji">http://randomguy32.de/unicode/charts/standardized-variants/#emoji</a>
Safari is better to display the characters.
Google Chrome and Opera have the same limitations: some characters are not supported (ex: section Phags-Pa).


<hr><h2 id="Whitespaces__separators">Whitespaces, separators</h2><hr>
22/05/2021
<a target="_blank" rel="noopener noreferrer" href="https://eev.ee/blog/2015/09/12/dark-corners-of-unicode/">https://eev.ee/blog/2015/09/12/dark-corners-of-unicode/</a>
A section about wcwidth.
A section about spaces:
    There are actually two definitions of whitespace in Unicode.
    Unicode assigns every codepoint a category, and has three categories for
    what sounds like whitespace:
        ‚ÄúSeparator, space‚Äù;
        ‚ÄúSeparator, line‚Äù;
        ‚ÄúSeparator, paragraph‚Äù.
    CR, LF, tab, and even vertical tab are all categorized as ‚ÄúOther, control‚Äù
    and not as separators.
    The only character in the ‚ÄúSeparator, line‚Äù category is U+2028 LINE SEPARATOR,
    and the only character in ‚ÄúSeparator, paragraph‚Äù is U+2029 PARAGRAPH SEPARATOR.
    Thankfully, all of these have the WSpace property.

    As an added wrinkle, the lone oddball character ‚Äú‚†Ä‚Äù renders like a space in most fonts.
    jlf: 2 cols x 3 lines of debossed dots.
    But it‚Äôs not whitespace, it‚Äôs not categorized as a separator, and it doesn‚Äôt have WSpace.
    It‚Äôs actually U+2800 BRAILLE PATTERN BLANK, the Braille character with none of the dots raised.
    (I say ‚Äúmost fonts‚Äù because I‚Äôve occasionally seen it rendered as a 2√ó4 grid of open circles.)


<hr><h2 id="Indic_languages">Indic languages</h2><hr>
This section illustrates that Unicode‚Äôs concepts like ‚Äúextended grapheme cluster‚Äù
are meant to provide some low-level, general segmentation, and are not going
to be enough for ideal experience for end users.

<a target="_blank" rel="noopener noreferrer" href="https://stackoverflow.com/questions/6805311/combining-devanagari-characters">https://stackoverflow.com/questions/6805311/combining-devanagari-characters</a>
Combining Devanagari characters
"‡§¨‡§ø‡§ï‡•ç‡§∞‡§Æ ‡§Æ‡•á‡§∞‡•ã ‡§®‡§æ‡§Æ ‡§π‡•ã"~text~graphemes==
    a GraphemeSupplier
     1  : T'‡§¨‡§ø'
     2  : T'‡§ï‡•ç'     &lt;-- According the comments, these 2 graphemes should be only one: ‡§ï‡•ç‡§∞
     3  : T'‡§∞'      &lt;-- even ICU doesn't support that... it's a tailored grapheme cluster
     4  : T'‡§Æ'
     5  : T' '
     6  : T'‡§Æ‡•á'
     7  : T'‡§∞‡•ã'
     8  : T' '
     9  : T'‡§®‡§æ'
     10 : T'‡§Æ'
     11 : T' '
     12 : T'‡§π‡•ã'
"‡§¨‡§ø‡§ï‡•ç‡§∞‡§Æ ‡§Æ‡•á‡§∞‡•ã ‡§®‡§æ‡§Æ ‡§π‡•ã"~text~characters==
    an Array (shape [18], 18 items)
     1  : ( "‡§¨"   U+092C Lo 1 "DEVANAGARI LETTER BA" )
     2  : ( "‡§ø"    U+093F Mc 0 "DEVANAGARI VOWEL SIGN I" )
     3  : ( "‡§ï"   U+0915 Lo 1 "DEVANAGARI LETTER KA" )
     4  : ( "‡•ç"    U+094D Mn 0 "DEVANAGARI SIGN VIRAMA" )           &lt;-- influence segmentation
     5  : ( "‡§∞"   U+0930 Lo 1 "DEVANAGARI LETTER RA" )
     6  : ( "‡§Æ"   U+092E Lo 1 "DEVANAGARI LETTER MA" )
     7  : ( " "   U+0020 Zs 1 "SPACE", "SP" )
     8  : ( "‡§Æ"   U+092E Lo 1 "DEVANAGARI LETTER MA" )
     9  : ( "‡•á"    U+0947 Mn 0 "DEVANAGARI VOWEL SIGN E" )
     10 : ( "‡§∞"   U+0930 Lo 1 "DEVANAGARI LETTER RA" )
     11 : ( "‡•ã"    U+094B Mc 0 "DEVANAGARI VOWEL SIGN O" )
     12 : ( " "   U+0020 Zs 1 "SPACE", "SP" )
     13 : ( "‡§®"   U+0928 Lo 1 "DEVANAGARI LETTER NA" )
     14 : ( "‡§æ"    U+093E Mc 0 "DEVANAGARI VOWEL SIGN AA" )
     15 : ( "‡§Æ"   U+092E Lo 1 "DEVANAGARI LETTER MA" )
     16 : ( " "   U+0020 Zs 1 "SPACE", "SP" )
     17 : ( "‡§π"   U+0939 Lo 1 "DEVANAGARI LETTER HA" )
     18 : ( "‡•ã"    U+094B Mc 0 "DEVANAGARI VOWEL SIGN O" )
In Devanagari, each grapheme cluster consists of an initial letter, optional
pairs of virama (vowel killer) and letter, and an optional vowel sign.
    virama = u'\N{DEVANAGARI SIGN VIRAMA}'
    cluster = u''
    last = None
    for c in s:
        cat = unicodedata.category(c)[0]
        if cat == 'M' or cat == 'L' and last == virama:
            cluster += c
        else:
            if cluster:
                yield cluster
            cluster = c
        last = c
    if cluster:
        yield cluster
---
Let's cover the grammar very quickly: The Devanagari Block.
As a developer, there are two character classes you'll want to concern yourself with:
Sign:
    This is a character that affects a previously-occurring character.
    Example, this character: ‡•ç. The light-colored circle indicates the location
    of the center of the character it is to be placed upon.
Letter / Vowel / Other:
    This is a character that may be affected by signs.
    Example, this character: ‡§ï.
Combination result of ‡•ç and ‡§ï: ‡§ï‡•ç. But combinations can extend, so ‡§ï‡•ç and ‡§∑‡§§‡§ø will
actually become ‡§ï‡•ç‡§∑‡§§‡§ø (in this case, we right-rotate the first character by 90 degrees,
modify some of the stylish elements, and attach it at the left side of the second character).


<a target="_blank" rel="noopener noreferrer" href="https://github.com/anoopkunchukuttan/indic_nlp_library">https://github.com/anoopkunchukuttan/indic_nlp_library</a>
The goal of the Indic NLP Library is to build Python based libraries for common
text processing and Natural Language Processing in Indian languages.
The library provides the following functionalities:
    Text Normalization
    Script Information
    Word Tokenization and Detokenization
    Sentence Splitting
    Word Segmentation
    Syllabification
    Script Conversion
    Romanization
    Indicization
    Transliteration
    Translation


<a target="_blank" rel="noopener noreferrer" href="https://news.ycombinator.com/item?id=20056966">https://news.ycombinator.com/item?id=20056966</a>
jlf: Devnagari seems to be an example where grapheme is not the right segmentation
"‡§á‡§Ç‡§°‡•á‡§ï‡•ç‡§∏" ‡§ï‡§æ ‡§ï‡•ç‡§Ø‡§æ ‡§Ö‡§∞‡•ç‡§• ‡§π‡•à?
Including the quote marks, spaces, and question mark, that's 18 characters.
as a native speaker, shouldn't they be considered 15 characters?
‡§ï‡•ç‡§∏, ‡§ï‡•ç‡§Ø‡§æ and ‡§∞‡•ç‡§• each form individual conjunct consonants.
Counting them as two would then beget the question as to why ‡§°‡•á is not considered
two characters too, seeing as it is formed by combining ‡§° and ‡§è, much like ‡§ï‡•ç‡§∏
is formed by combining ‡§ï‡•ç and ‡§∏.
...
Devnagari allows simple characters to form compound characters.
Regarding ‡§ï‡•ç‡§∏ and ‡§°‡•á, the difference between them is that the former is a combination
of two consonants (pronounced "ks") while the latter is formed by a consonant and
a vowel ("de"). However, looking at the visual representation is wrong, since ‡§°‡§æ
(consonant+vowel) would also look like two characters.


<a target="_blank" rel="noopener noreferrer" href="https://slidetodoc.com/indic-text-segmentation-presented-by-swaran-lata-senior/">https://slidetodoc.com/indic-text-segmentation-presented-by-swaran-lata-senior/</a>
INDIC TEXT SEGMENTATION


<a target="_blank" rel="noopener noreferrer" href="https://github.com/w3c/iip/issues/34">https://github.com/w3c/iip/issues/34</a>
the final rendered state of the text is what influences the segmentation,
rather than the sequence of code points used.


<a target="_blank" rel="noopener noreferrer" href="https://docs.microsoft.com/en-us/typography/">https://docs.microsoft.com/en-us/typography/</a>

<a target="_blank" rel="noopener noreferrer" href="https://docs.microsoft.com/en-us/typography/script-development/tamil">https://docs.microsoft.com/en-us/typography/script-development/tamil</a>
Developing OpenType Fonts for Tamil Script
The first step is to analyze the input text and break it into syllable clusters.
Then apply font features and computes ligatures and combine marks.


<a target="_blank" rel="noopener noreferrer" href="https://docs.microsoft.com/en-us/typography/script-development/devanagari">https://docs.microsoft.com/en-us/typography/script-development/devanagari</a>
Developing OpenType Fonts for Devanagari Script


<hr><h2 id="Korean">Korean</h2><hr>
22/05/2021
<a target="_blank" rel="noopener noreferrer" href="http://gernot-katzers-spice-pages.com/var/korean_hangul_unicode.html">http://gernot-katzers-spice-pages.com/var/korean_hangul_unicode.html</a>
The Korean Writing System


<hr><h2 id="Japanese">Japanese</h2><hr>
<a target="_blank" rel="noopener noreferrer" href="https://heistak.github.io/your-code-displays-japanese-wrong/">https://heistak.github.io/your-code-displays-japanese-wrong/</a>
<a target="_blank" rel="noopener noreferrer" href="https://news.ycombinator.com/item?id=29022906">https://news.ycombinator.com/item?id=29022906</a>


<hr><h2 id="String_Matching">String Matching</h2><hr>
<a target="_blank" rel="noopener noreferrer" href="https://www.w3.org/TR/charmod-norm/">https://www.w3.org/TR/charmod-norm/</a>
String matching

Case folding is the process of making two texts which differ only in case identical for comparison purposes, that is, it is meant for the purpose of string matching.
This is distinct from case mapping, which is primarily meant for display purposes.
As with the default case mappings, Unicode defines default case fold mappings ("case folding") for each Unicode code point.


<hr><h2 id="Fuzzy_String_Matching">Fuzzy String Matching</h2><hr>
29/05/2021
<a target="_blank" rel="noopener noreferrer" href="https://github.com/logannc/fuzzywuzzy-rs">https://github.com/logannc/fuzzywuzzy-rs</a>
Rust port of the Python fuzzywuzzy
<a target="_blank" rel="noopener noreferrer" href="https://github.com/seatgeek/fuzzywuzzy">https://github.com/seatgeek/fuzzywuzzy</a> --&gt; moved to <a target="_blank" rel="noopener noreferrer" href="https://github.com/seatgeek/thefuzz">https://github.com/seatgeek/thefuzz</a>


<hr><h2 id="Levenshtein_distance_and_string_similarity">Levenshtein distance and string similarity</h2><hr>
<a target="_blank" rel="noopener noreferrer" href="https://github.com/ztane/python-Levenshtein/">https://github.com/ztane/python-Levenshtein/</a>
The Levenshtein Python C extension module contains functions for fast computation of Levenshtein distance and string similarity


<hr><h2 id="String_comparison">String comparison</h2><hr>
31/05/2021
<a target="_blank" rel="noopener noreferrer" href="https://stackoverflow.com/questions/49662585/how-do-i-compare-a-unicode-string-that-has-different-bytes-but-the-same-value">https://stackoverflow.com/questions/49662585/how-do-i-compare-a-unicode-string-that-has-different-bytes-but-the-same-value</a>
A pair NFC considers different but a user might consider the same is '¬µ' (MICRO SIGN) and 'Œº' (GREEK SMALL LETTER MU).
NFKC will collapse these two.


<a target="_blank" rel="noopener noreferrer" href="http://www.unicode.org/reports/tr10/">http://www.unicode.org/reports/tr10/</a>
Unicode¬Æ Technical Standard #10
UNICODE COLLATION ALGORITHM
Collation is the general term for the process and function of determining the sorting order of strings of characters.
Collation varies according to language and culture: Germans, French and Swedes sort the same characters differently.
It may also vary by specific application: even within the same language, dictionaries may sort differently than phonebooks or book indices.
For non-alphabetic scripts such as East Asian ideographs, collation can be either phonetic or based on the appearance of the character.
Collation can also be customized according to user preference, such as ignoring punctuation or not, putting uppercase before lowercase (or vice versa), and so on.


<a target="_blank" rel="noopener noreferrer" href="https://en.wikipedia.org/wiki/Unicode_equivalence">https://en.wikipedia.org/wiki/Unicode_equivalence</a>
Short definition of NFD, NFC, NFKD, NFKC

    In this article, a short paragraph which confirms that it's important to keep
    the original string unchanged !
    Errors due to normalization differences
    When two applications share Unicode data, but normalize them differently, errors and data loss can result.
    In one specific instance, OS X normalized Unicode filenames sent from the Samba file- and printer-sharing software.
    Samba did not recognise the altered filenames as equivalent to the original, leading to data loss.[4][5]
    Resolving such an issue is non-trivial, as normalization is not losslessly invertible.
    <a target="_blank" rel="noopener noreferrer" href="http://sourceforge.net/p/netatalk/bugs/348/">http://sourceforge.net/p/netatalk/bugs/348/</a>
    #348 volcharset:UTF8 doesn't work from Mac


<a target="_blank" rel="noopener noreferrer" href="http://unicode.org/faq/normalization.html">http://unicode.org/faq/normalization.html</a>
Mode detailled description of normalization


PHP
    <a target="_blank" rel="noopener noreferrer" href="http://php.net/manual/en/collator.compare.php">http://php.net/manual/en/collator.compare.php</a>
    Collator::compare -- collator_compare ‚Äî Compare two Unicode strings
    Object oriented style
        public int Collator::compare ( string $str1 , string $str2 )
    Procedural style
        int collator_compare ( Collator $coll , string $str1 , string $str2 )


    <a target="_blank" rel="noopener noreferrer" href="http://php.net/manual/en/class.collator.php">http://php.net/manual/en/class.collator.php</a>
    Provides string comparison capability with support for appropriate locale-sensitive sort orderings.


Swift
    <a target="_blank" rel="noopener noreferrer" href="https://developer.apple.com/library/prerelease/watchos/documentation/Swift/Conceptual/Swift_Programming_Language/StringsAndCharacters.html">https://developer.apple.com/library/prerelease/watchos/documentation/Swift/Conceptual/Swift_Programming_Language/StringsAndCharacters.html</a>
        Two String values (or two Character values) are considered equal if their extended grapheme clusters are canonically equivalent.
        Extended grapheme clusters are canonically equivalent if they have the same linguistic meaning and appearance,
        even if they are composed from different Unicode scalars behind the scenes.

        .characters.count
        for character in dogString.characters
        for codeUnit in dogString.utf8
        for codeUnit in dogString.utf16
        for scalar in dogString.unicodeScalars

        Nothing about ordered comparison in Swift doc ?

    <a target="_blank" rel="noopener noreferrer" href="http://oleb.net/blog/2014/07/swift-strings/">http://oleb.net/blog/2014/07/swift-strings/</a>

        Ordering strings with the &lt; and &gt; operators uses the default Unicode collation algorithm.
        In the example below, "√©" is smaller than i because the collation algorithm specifies
        that characters with combining marks follow right after their base character.
            "r√©sum√©" &lt; "risotto" // -&gt; true
        The String type does not (yet?) come with a method to specify the language to use for collation.
        You should continue to use
            -[NSString compare:options:range:locale:]
        or
            -[NSString localizedCompare:]
        if you need to sort strings that are shown to the user.

        In this example, specifying a locale that uses the German phonebook collation yields a different result than the default string ordering:
            let muffe = "Muffe"
            let m√ºller = "M√ºller"
            muffe &lt; m√ºller // -&gt; true

            // Comparison using an US English locale yields the same result
            let muffeRange = muffe.startIndex..&lt;muffe.endIndex
            let en_US = NSLocale(localeIdentifier: "en_US")
            muffe.compare(m√ºller, options: nil, range: muffeRange, locale: en_US) // -&gt; .OrderedAscending

            // Germany phonebook ordering treats "√º" as "ue".
            // Thus, "M√ºller" &lt; "Muffe"
            let de_DE_phonebook = NSLocale(localeIdentifier: "de_DE@collation=phonebook")
            muffe.compare(m√ºller, options: nil, range: muffeRange, locale: de_DE_phonebook) // -&gt; .OrderedDescending


Java
    <a target="_blank" rel="noopener noreferrer" href="https://jcdav.is/2016/09/01/How-the-JVM-compares-your-strings/">https://jcdav.is/2016/09/01/How-the-JVM-compares-your-strings/</a>
    How the JVM compares your strings using the craziest x86 instruction you've never heard of.
    ---
    A comment about this article:
    PCMPxSTRx is no longer faster than equivalent "simple" vector instruction sequences for straightforward comparisons
    (this had already been the case for a few years when that article was written, which is curious).
    It can be used productively (with some care) for some other operations like substring matching,
    but that's not as much of a heavy-hitter.
    There's a bunch of string stuff that will benefit from general vectorization, and which is absolutely on our roadmap to tackle,
    but using the PCMPxSTRx instructions specifically isn't a source of wins on the most important operations


C#
    <a target="_blank" rel="noopener noreferrer" href="https://docs.microsoft.com/en-us/dotnet/standard/base-types/comparing">https://docs.microsoft.com/en-us/dotnet/standard/base-types/comparing</a>
    <a target="_blank" rel="noopener noreferrer" href="https://docs.microsoft.com/en-us/dotnet/core/extensions/performing-culture-insensitive-string-comparisons">https://docs.microsoft.com/en-us/dotnet/core/extensions/performing-culture-insensitive-string-comparisons</a>


<hr><h2 id="Encodings">Encodings</h2><hr>
30/05/2021
<a target="_blank" rel="noopener noreferrer" href="https://datatracker.ietf.org/doc/html/rfc8259">https://datatracker.ietf.org/doc/html/rfc8259</a>
The JavaScript Object Notation (JSON) Data Interchange Format
See this section about strings and encoding:
<a target="_blank" rel="noopener noreferrer" href="https://datatracker.ietf.org/doc/html/rfc8259#section-7">https://datatracker.ietf.org/doc/html/rfc8259#section-7</a>


<hr><h2 id="JSON">JSON</h2><hr>
<a target="_blank" rel="noopener noreferrer" href="https://www.reddit.com/r/programming/comments/q5vmxc/parsing_json_is_a_minefield_2018/">https://www.reddit.com/r/programming/comments/q5vmxc/parsing_json_is_a_minefield_2018/</a>
<a target="_blank" rel="noopener noreferrer" href="https://seriot.ch/projects/parsing_json.html">https://seriot.ch/projects/parsing_json.html</a>
Parsing JSON is a Minefield
Search for "unicode"


<hr><h2 id="TOML_serialization_format">TOML serialization format</h2><hr>
<a target="_blank" rel="noopener noreferrer" href="https://github.com/toml-lang/toml">https://github.com/toml-lang/toml</a>
Tom's Obvious, Minimal Language
TOML is a nice serialization format for human-maintained data structures.
It‚Äôs line-delimited and‚Äîof course!‚Äîallows comments, and any Unicode code point can be expressed in simple hexadecimal.
TOML is fairly new, and its specification is still in flux;


<hr><h2 id="CBOR_Concise_Binary_Representation">CBOR Concise Binary Representation</h2><hr>
<a target="_blank" rel="noopener noreferrer" href="https://cbor.io/">https://cbor.io/</a>
RFC 8949 Concise Binary Object Representation
CBOR improves upon JSON‚Äôs efficiency and also allows for storage of binary strings.
Whereas JSON encoders must stringify numbers and escape all strings,
CBOR stores numbers ‚Äúliterally‚Äù and prefixes strings with their length,
which obviates the need to escape those strings.


<a target="_blank" rel="noopener noreferrer" href="https://www.rfc-editor.org/rfc/rfc8949.html">https://www.rfc-editor.org/rfc/rfc8949.html</a>
RFC 8949 Concise Binary Object Representation (CBOR)
In contrast to formats such as JSON, the Unicode characters in this type are never escaped.
Thus, a newline character (U+000A) is always represented in a string as the byte 0x0a,
and never as the bytes 0x5c6e (the characters "\" and "n")
nor as 0x5c7530303061 (the characters "\", "u", "0", "0", "0", and "a").


<hr><h2 id="Binary_encoding_in_Unicode">Binary encoding in Unicode</h2><hr>
10/07/2021
<a target="_blank" rel="noopener noreferrer" href="https://qntm.org/unicodings">https://qntm.org/unicodings</a>
Efficiently encoding binary data in Unicode
in UTF-8, use Base64 or Base85
in UTF-16, use Base32768
in UTF-32, use Base65536


<a target="_blank" rel="noopener noreferrer" href="https://qntm.org/safe">https://qntm.org/safe</a>
What makes a Unicode code point safe?


<a target="_blank" rel="noopener noreferrer" href="https://github.com/qntm/safe-code-point">https://github.com/qntm/safe-code-point</a>
Ascertains whether a Unicode code point is 'safe' for the purposes of encoding binary data


<a target="_blank" rel="noopener noreferrer" href="https://github.com/qntm/base2048">https://github.com/qntm/base2048</a>
Binary encoding optimised for Twitter
Originally, Twitter allowed Tweets to be at most 140 characters.
On 26 September 2017, Twitter allowed 280 characters.
Maximum Tweet length is indeed 280 Unicode code points.
Twitter divides Unicode into 4,352 "light" code points (U+0000 to U+10FF inclusive)
and 1,109,760 "heavy" code points (U+1100 to U+10FFFF inclusive).
Base2048 solely uses light characters, which means a new "long" Tweet can contain
at most 280 characters of Base2048. Base2048 is an 11-bit encoding, so those 280
characters encode 3080 bits i.e. 385 octets of data, significantly better than Base65536.


<a target="_blank" rel="noopener noreferrer" href="https://github.com/qntm/base65536">https://github.com/qntm/base65536</a>
Unicode's answer to Base64
Base2048 renders Base65536 obsolete for its original intended purpose of sending
binary data through Twitter.
However, Base65536 remains the state of the art for sending binary data through
text-based systems which naively count Unicode code points, particularly those
using the fixed-width UTF-32 encoding.


<hr><h2 id="Invalid_format">Invalid format</h2><hr>
22/07/2021
<a target="_blank" rel="noopener noreferrer" href="https://stackoverflow.com/questions/52131881/does-the-winapi-ever-validate-utf-16">https://stackoverflow.com/questions/52131881/does-the-winapi-ever-validate-utf-16</a>
Does the WinApi ever validate UTF-16?
Windows wide characters are arbitrary 16-bit numbers (formerly called "UCS-2",
before the Unicode Standard Consortium purged that notation). So you cannot
assume that it will be a valid UTF-16 sequence. (MultiByteToWideChar is a
notable exception that does return only UTF-16)


28/07/2021
<a target="_blank" rel="noopener noreferrer" href="https://invisible-island.net/xterm/bad-utf8/">https://invisible-island.net/xterm/bad-utf8/</a>
Unicode replacement character in the Linux console.
This test text examines, how UTF-8 decoders handle various types of
corrupted or otherwise interesting UTF-8 sequences.
jlf : difficult to understand what is the conclusion...
What I notice in this review is :
Unicode 10.0.0's chapter 3 (June 2017): each of the ill-formed code units is separately replaced by U+FFFD.
That recommendation first appeared in Unicode 6's chapter 3 on conformance (February 2011).
However the comments about ‚Äúbest practice‚Äù were removed in Unicode 11.0.0 (June 2018).
The W3C WHATWG page entitled Encoding Standard started in January 2013.
    The constraints in the utf-8 decoder above match ‚ÄúBest Practices for Using
    U+FFFD‚Äù from the Unicode standard. No other behavior is permitted per the
    Encoding Standard (other algorithms that achieve the same result are
    obviously fine, even encouraged).
Although Unicode withdrew the recommendation more than two years ago, to date (August 2020) that is not yet corrected in the WHATWG page.


30/07/2021
<a target="_blank" rel="noopener noreferrer" href="https://hsivonen.fi/broken-utf-8/">https://hsivonen.fi/broken-utf-8/</a>
---
The Unicode Technical Committee retracted the change in its meeting on August 3
2017, so the concern expressed below is now moot.
---
Not all byte sequences are valid UTF-8. When decoding potentially invalid UTF-8
input into a valid Unicode representation, something has to be done about invalid input.
The na√Øve answer is to ignore invalid input until finding valid input again (i.e.
finding the next byte that has a lead-byte value), but this is dangerous and
should never be done. The danger is that silently dropping bogus bytes might
make a string that didn‚Äôt look dangerous with the bogus bytes present become
valid active content. Most simply, &lt;scrÔøΩipt&gt; (ÔøΩ standing in for a bogus byte)
could become &lt;script&gt; if the error is ignored. So it‚Äôs non-controversial that
every sequence of bogus bytes should result in at least one REPLACEMENT CHARACTER
and that the next lead-valued byte is the first byte that‚Äôs no longer part of
the invalid sequence.
But how many REPLACEMENT CHARACTERs should be generated for a sequence of
multiple bogus bytes?
jlf: the answer is not clear to me...


<hr><h2 id="Mojibake">Mojibake</h2><hr>
<a target="_blank" rel="noopener noreferrer" href="https://github.com/LuminosoInsight/python-ftfy">https://github.com/LuminosoInsight/python-ftfy</a>
ftfy can fix mojibake (encoding mix-ups), by detecting patterns of characters
that were clearly meant to be UTF-8 but were decoded as something else


03/07/2021
Notebook in python-ftfy:
Services such as Slack and Discord don't use Unicode for their emoji.
They use ASCII strings like :green-heart: and turn them into images.
These won't help you test anything.
I recommend getting emoji for your test cases by copy-pasting them from emojipedia.org.
<a target="_blank" rel="noopener noreferrer" href="https://emojipedia.org/">https://emojipedia.org/</a>


<hr><h2 id="Filenames">Filenames</h2><hr>
<a target="_blank" rel="noopener noreferrer" href="https://opensource.apple.com/source/subversion/subversion-52/subversion/notes/unicode-composition-for-filenames.auto.html">https://opensource.apple.com/source/subversion/subversion-52/subversion/notes/unicode-composition-for-filenames.auto.html</a>
2 problems follow:
 1) We can't generally depend on the OS to give us back the
     exact filename we gave it
 2) The same filename may be encoded in different codepoints


<hr><h2 id="WTF8">WTF8</h2><hr>
<a target="_blank" rel="noopener noreferrer" href="https://news.ycombinator.com/item?id=9611710">https://news.ycombinator.com/item?id=9611710</a>
The WTF-8 encoding (simonsapin.github.io)
<a target="_blank" rel="noopener noreferrer" href="https://news.ycombinator.com/item?id=9613971">https://news.ycombinator.com/item?id=9613971</a>
<a target="_blank" rel="noopener noreferrer" href="https://simonsapin.github.io/wtf-8/#acknowledgments">https://simonsapin.github.io/wtf-8/#acknowledgments</a>
Thanks to Coralie Mercier for coining the name WTF-8.
---
The name is unserious but the project is very serious, its writer has responded
to a few comments and linked to a presentation of his on the subject[0].
It's an extension of UTF-8 used to bridge UTF-8 and UCS2-plus-surrogates:
while UTF8 is the modern encoding you have to interact with legacy systems,
for UNIX's bags of bytes you may be able to assume UTF8 (possibly ill-formed)
but a number of other legacy systems used UCS2 and added visible surrogates
(rather than proper UTF-16) afterwards.
Windows and NTFS, Java, UEFI, Javascript all work with UCS2-plus-surrogates.
Having to interact with those systems from a UTF8-encoded world is an issue
because they don't guarantee well-formed UTF-16, they might contain unpaired
surrogates which can't be decoded to a codepoint allowed in UTF-8 or UTF-32
(neither allows unpaired surrogates, for obvious reasons).
WTF8 extends UTF8 with unpaired surrogates (and unpaired surrogates only,
paired surrogates from valid UTF16 are decoded and re-encoded to a proper
UTF8-valid codepoint) which allows interaction with legacy UCS2 systems.
WTF8 exists solely as an internal encoding (in-memory representation),
but it's very useful there.
[0] <a target="_blank" rel="noopener noreferrer" href="http://exyr.org/2015/!!Con_WTF-8/slides.pdf">http://exyr.org/2015/!!Con_WTF-8/slides.pdf</a>

<a target="_blank" rel="noopener noreferrer" href="https://twitter.com/koalie/status/506821684687413248">https://twitter.com/koalie/status/506821684687413248</a>
Coralie Mercier
@koalie
I have a hunch we use "wtf-8" encoding.
Appreciate the irony of:
"√É∆í√Ü‚Äô√É‚Äö√Ü‚Äô√É∆í√Ç¬¢√É‚Äö√¢‚Äö¬¨√É‚Äö√Ö¬°√É∆í√Ü‚Äô√É‚Äö√¢‚Ç¨≈°√É∆í√¢‚Ç¨≈°√É‚Äö√Ç the future of publishing at W3C"


16/07/2021
Windows allows unpaired surrogates in filenames


<a target="_blank" rel="noopener noreferrer" href="https://github.com/golang/go/issues/32334">https://github.com/golang/go/issues/32334</a>
syscall: Windows filenames with unpaired surrogates are not handled correctly #32334


<a target="_blank" rel="noopener noreferrer" href="https://github.com/rust-lang/rust/issues/12056">https://github.com/rust-lang/rust/issues/12056</a>
path: Windows paths may contain non-utf8-representable sequences #12056
I don't know the precise details, but there exist portions of Windows in which
paths are UCS2 rather than UTF-16. I ignored it because I thought it wasn't going
to be an issue but at some point someone (and I wish I could remember who) showed
me some output that showed that they were actually getting a UCS2 path from some
Windows call and Path was unable to parse it.
---
JLF: this is the birth of WTF-8 in 2014.
The result is:
<a target="_blank" rel="noopener noreferrer" href="https://simonsapin.github.io/wtf-8/#16-bit-code-unit">https://simonsapin.github.io/wtf-8/#16-bit-code-unit</a>


<hr><h2 id="Indexation_of_UTF_8_strings">Indexation of UTF-8 strings</h2><hr>
<a target="_blank" rel="noopener noreferrer" href="https://nullprogram.com/blog/2019/05/29/">https://nullprogram.com/blog/2019/05/29/</a>


ObjectIcon
    <a target="_blank" rel="noopener noreferrer" href="http://objecticon.sourceforge.net/Unicode.html">http://objecticon.sourceforge.net/Unicode.html</a>
    ucs (standing for Unicode character string) is a new builtin type, whose behaviour closely mirrors
    that of the conventional Icon string. It operates by providing a wrapper around a conventional
    conventional Icon string, which must be in utf-8 format. This has several advantages, and only one
    serious disadvantage, namely that a utf-8 string is not randomly accessible, in the sense that one
    cannot say where the representation for unicode character i begins. To alleviate this disadvantage,
    the ucs type maintains an index of offsets into the utf-8 string to make random access faster. The
    size of the index is only a few percent of the total allocation for the ucs object.
Jlf: I made a code review, but could not understand how they do that :-(


<hr><h2 id="Rope">Rope</h2><hr>
<a target="_blank" rel="noopener noreferrer" href="https://github.com/josephg/librope">https://github.com/josephg/librope</a>
Little C library for heavyweight utf-8 strings (rope).


<a target="_blank" rel="noopener noreferrer" href="https://news.ycombinator.com/item?id=8065608">https://news.ycombinator.com/item?id=8065608</a>
Discussion about ropes, ideal of strings...


<a target="_blank" rel="noopener noreferrer" href="https://github.com/xi-editor/xi-editor/blob/e8065a3993b80af0aadbca0e50602125d60e4e38/doc/rope_science/rope_science_03.md">https://github.com/xi-editor/xi-editor/blob/e8065a3993b80af0aadbca0e50602125d60e4e38/doc/rope_science/rope_science_03.md</a>


<hr><h2 id="ICU">ICU</h2><hr>
<a target="_blank" rel="noopener noreferrer" href="http://stackoverflow.com/questions/8253033/what-open-source-c-or-c-libraries-can-convert-arbitrary-utf-32-to-nfc">http://stackoverflow.com/questions/8253033/what-open-source-c-or-c-libraries-can-convert-arbitrary-utf-32-to-nfc</a>
What open source C or C++ libraries can convert arbitrary UTF-32 to NFC?

std::string normalize(const std::string &amp;unnormalized_utf8) {
    // FIXME: until ICU supports doing normalization over a UText
    // interface directly on our UTF-8, we'll use the insanely less
    // efficient approach of converting to UTF-16, normalizing, and
    // converting back to UTF-8.

    // Convert to UTF-16 string
    auto unnormalized_utf16 = icu::UnicodeString::fromUTF8(unnormalized_utf8);

    // Get a pointer to the global NFC normalizer
    UErrorCode icu_error = U_ZERO_ERROR;
    const auto *normalizer = icu::Normalizer2::getInstance(nullptr, "nfc", UNORM2_COMPOSE, icu_error);
    assert(U_SUCCESS(icu_error));

    // Normalize our string
    icu::UnicodeString normalized_utf16;
    normalizer-&gt;normalize(unnormalized_utf16, normalized_utf16, icu_error);
    assert(U_SUCCESS(icu_error));

    // Convert back to UTF-8
    std::string normalized_utf8;
    normalized_utf16.toUTF8String(normalized_utf8);

    return normalized_utf8;
}


<hr><h2 id="ICU_bindings">ICU bindings</h2><hr>
02/06/2021
<a target="_blank" rel="noopener noreferrer" href="https://gitlab.pyicu.org/main/pyicu">https://gitlab.pyicu.org/main/pyicu</a>
Python extension wrapping the ICU C++ libraries.


02/06/2021
<a target="_blank" rel="noopener noreferrer" href="https://docs.microsoft.com/en-us/windows/win32/intl/international-components-for-unicode--icu-">https://docs.microsoft.com/en-us/windows/win32/intl/international-components-for-unicode--icu-</a>
In Windows 10 Creators Update, ICU was integrated into Windows, making the C APIs and data publicly accessible.
The version of ICU in Windows only exposes the C APIs.
It is impossible to ever expose the C++ APIs due to the lack of a stable ABI in C++.
Getting started
1) Your application needs to target Windows 10 Version 1703 (Creators Update) or higher.
2) Add in the header:
    #include &lt;icu.h&gt;
3) Link to:
    icu.lib
Example:
    void FormatDateTimeICU()
    {
        UErrorCode status = U_ZERO_ERROR;

        // Create a ICU date formatter, using only the 'short date' style format.
        UDateFormat* dateFormatter = udat_open(UDAT_NONE, UDAT_SHORT, nullptr, nullptr, -1, nullptr, 0, &amp;status);

        if (U_FAILURE(status))
        {
            ErrorMessage(L"Failed to create date formatter.");
            return;
        }

        // Get the current date and time.
        UDate currentDateTime = ucal_getNow();

        int32_t stringSize = 0;

        // Determine how large the formatted string from ICU would be.
        stringSize = udat_format(dateFormatter, currentDateTime, nullptr, 0, nullptr, &amp;status);

        if (status == U_BUFFER_OVERFLOW_ERROR)
        {
            status = U_ZERO_ERROR;
            // Allocate space for the formatted string.
            auto dateString = std::make_unique&lt;UChar[]&gt;(stringSize + 1);

            // Format the date time into the string.
            udat_format(dateFormatter, currentDateTime, dateString.get(), stringSize + 1, nullptr, &amp;status);

            if (U_FAILURE(status))
            {
                ErrorMessage(L"Failed to format the date time.");
                return;
            }

            // Output the formatted date time.
            OutputMessage(dateString.get());
        }
        else
        {
            ErrorMessage(L"An error occured while trying to determine the size of the formatted date time.");
            return;
        }

        // We need to close the ICU date formatter.
        udat_close(dateFormatter);
    }


<a target="_blank" rel="noopener noreferrer" href="http://www.boost.org/doc/libs/1_58_0/libs/locale/doc/html/index.html">http://www.boost.org/doc/libs/1_58_0/libs/locale/doc/html/index.html</a>
Boost.Locale creates the natural glue between the C++ locales framework, iostreams, and the powerful ICU library


<a target="_blank" rel="noopener noreferrer" href="http://blog.lukhnos.org/post/6441462604/using-os-xs-built-in-icu-library-in-your-own">http://blog.lukhnos.org/post/6441462604/using-os-xs-built-in-icu-library-in-your-own</a>
Using OS X‚Äôs Built-in ICU Library in Your Own Project


<hr><h2 id="utfcpp">utfcpp</h2><hr>
<a target="_blank" rel="noopener noreferrer" href="https://github.com/nemtrif/utfcpp/">https://github.com/nemtrif/utfcpp/</a>
referenced from <a target="_blank" rel="noopener noreferrer" href="https://corp.unicode.org/pipermail/unicode/2020-April/008582.html">https://corp.unicode.org/pipermail/unicode/2020-April/008582.html</a>
Basic Unicode character/string support absent even in modern C++


<hr><h2 id="Twitter_text_parsing">Twitter text parsing</h2><hr>
<a target="_blank" rel="noopener noreferrer" href="https://github.com/twitter/twitter-text">https://github.com/twitter/twitter-text</a>
Twitter Text Libraries. This code is used at Twitter to tokenize and parse text
to meet the expectations for what can be used on the platform.

<a target="_blank" rel="noopener noreferrer" href="https://swiftpack.co/package/nysander/twitter-text">https://swiftpack.co/package/nysander/twitter-text</a>
This is the Swift implementation of the twitter-text parsing library.
The library has methods to parse Tweets and calculate length, validity, parse @mentions, #hashtags, URLs, and more.


<hr><h2 id="terminal___console">terminal / console</h2><hr>
<a target="_blank" rel="noopener noreferrer" href="https://www.reddit.com/r/bash/comments/wfbf3w/determine_if_the_termconsole_supports_utf8/">https://www.reddit.com/r/bash/comments/wfbf3w/determine_if_the_termconsole_supports_utf8/</a>
Determine if the term/console supports UTF8?


<hr><h2 id="Language_comparison">Language comparison</h2><hr>
<a target="_blank" rel="noopener noreferrer" href="https://blog.kdheepak.com/my-unicode-cheat-sheet">https://blog.kdheepak.com/my-unicode-cheat-sheet</a>
Vim, Python, Julia and Rust.


<hr><h2 id="Regular_expressions">Regular expressions</h2><hr>
<a target="_blank" rel="noopener noreferrer" href="https://www.regular-expressions.info/unicode.html">https://www.regular-expressions.info/unicode.html</a>
\X matches a grapheme


<a target="_blank" rel="noopener noreferrer" href="https://pypi.org/project/regex/">https://pypi.org/project/regex/</a>
&gt;&gt;&gt; a = "‡§¨‡§ø‡§ï‡•ç‡§∞‡§Æ ‡§Æ‡•á‡§∞‡•ã ‡§®‡§æ‡§Æ ‡§π‡•ã"
&gt;&gt;&gt; regex.findall(r'\X', a)
['‡§¨‡§ø', '‡§ï‡•ç', '‡§∞', '‡§Æ', ' ', '‡§Æ‡•á', '‡§∞‡•ã', ' ', '‡§®‡§æ', '‡§Æ', ' ', '‡§π‡•ã']
---
<a target="_blank" rel="noopener noreferrer" href="https://regex101.com/r/eD0eZ9/1">https://regex101.com/r/eD0eZ9/1</a>
---
jlf: the results above are correct extended grapheme clusters, but tailored
grapheme clusters will group '‡§ï‡•ç' '‡§∞' in one cluster ‡§ï‡•ç‡§∞


<hr><h2 id="Ada_lang">Ada lang</h2><hr>
<a target="_blank" rel="noopener noreferrer" href="https://docs.adacore.com/live/wave/xmlada/html/xmlada_ug/unicode.html">https://docs.adacore.com/live/wave/xmlada/html/xmlada_ug/unicode.html</a>

<a target="_blank" rel="noopener noreferrer" href="http://www.dmitry-kazakov.de/ada/strings_edit.htm">http://www.dmitry-kazakov.de/ada/strings_edit.htm</a>

UXStrings Ada Unicode Extended Strings
<a target="_blank" rel="noopener noreferrer" href="https://www.reddit.com/r/ada/comments/t4hpip/ann_uxstrings_package_available_uxs_20220226/">https://www.reddit.com/r/ada/comments/t4hpip/ann_uxstrings_package_available_uxs_20220226/</a>
<a target="_blank" rel="noopener noreferrer" href="https://github.com/Blady-Com/UXStrings">https://github.com/Blady-Com/UXStrings</a>

<hr><h2 id="C___lang__Boost">C++ lang, Boost</h2><hr>
02/06/2021
<a target="_blank" rel="noopener noreferrer" href="http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2019/p1238r1.html">http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2019/p1238r1.html</a>
    SG16 initial Unicode direction and guidance for C++20 and beyond.
<a target="_blank" rel="noopener noreferrer" href="https://github.com/sg16-unicode/sg16">https://github.com/sg16-unicode/sg16</a>
    SG16 is an ISO/IEC JTC1/SC22/WG21 C++ study group tasked with improving Unicode and text processing support within the C++ standard.


01/06/2021
Zach Laine
<a target="_blank" rel="noopener noreferrer" href="https://www.youtube.com/watch?v=944GjKxwMBo">https://www.youtube.com/watch?v=944GjKxwMBo</a>
<a target="_blank" rel="noopener noreferrer" href="https://tzlaine.github.io/text/doc/html/boost_text__proposed_/the_text_layer.html">https://tzlaine.github.io/text/doc/html/boost_text__proposed_/the_text_layer.html</a>
The Text Layer
<a target="_blank" rel="noopener noreferrer" href="https://tzlaine.github.io/text/doc/html/">https://tzlaine.github.io/text/doc/html/</a>
Chapter 1. Boost.Text (Proposed) - 2018
<a target="_blank" rel="noopener noreferrer" href="https://github.com/tzlaine/text">https://github.com/tzlaine/text</a>
    last commit :
        master                          26/09/2020
        boost_serialization             24/10/2019
        coroutines                      25/08/2020
        experimental                    13/11/2019
        gh-pages                        04/09/2020
        optimization                    27/10/2019
        rope_free_fn_reimplementation   26/07/2020
No longer working on this project ?


14/06/2021
<a target="_blank" rel="noopener noreferrer" href="https://hsivonen.fi/non-unicode-in-cpp/">https://hsivonen.fi/non-unicode-in-cpp/</a>
Same contents in sg16 mailing list + feedbacks
<a target="_blank" rel="noopener noreferrer" href="https://lists.isocpp.org/sg16/2019/04/0309.php">https://lists.isocpp.org/sg16/2019/04/0309.php</a>


03/07/2021
<a target="_blank" rel="noopener noreferrer" href="https://news.ycombinator.com/item?id=27695412">https://news.ycombinator.com/item?id=27695412</a>
Any Encoding, Ever ‚Äì ztd.text and Unicode for C++


14/07/2021
<a target="_blank" rel="noopener noreferrer" href="https://hsivonen.fi/non-unicode-in-cpp/">https://hsivonen.fi/non-unicode-in-cpp/</a>
It‚Äôs Time to Stop Adding New Features for Non-Unicode Execution Encodings in C++
The Microsoft Code Page 932 Issue


<a target="_blank" rel="noopener noreferrer" href="https://stackoverflow.com/questions/58878651/what-is-the-printf-formatting-character-for-char8-t/58895428#58895428.">https://stackoverflow.com/questions/58878651/what-is-the-printf-formatting-character-for-char8-t/58895428#58895428.</a>
What is the printf() formatting character for char8_t *?
jlf: todo read it? not sure yet if it's useful to read.
Referenced from <a target="_blank" rel="noopener noreferrer" href="https://corp.unicode.org/pipermail/unicode/2020-April/008579.html">https://corp.unicode.org/pipermail/unicode/2020-April/008579.html</a>
Basic Unicode character/string support absent even in modern C++


<hr><h2 id="DotNet__CoreFx">DotNet, CoreFx</h2><hr>
28/07/2021
<a target="_blank" rel="noopener noreferrer" href="https://github.com/dotnet/corefxlab/issues/2368">https://github.com/dotnet/corefxlab/issues/2368</a>
Scenarios and Design Philosophy - UTF-8 string support

    <a target="_blank" rel="noopener noreferrer" href="https://gist.github.com/GrabYourPitchforks/901684d0aa1d2440eb378d847cfc8607">https://gist.github.com/GrabYourPitchforks/901684d0aa1d2440eb378d847cfc8607</a> (jlf: replaced by the following URL)
    <a target="_blank" rel="noopener noreferrer" href="https://github.com/dotnet/corefx/issues/34094">https://github.com/dotnet/corefx/issues/34094</a> (go directly to next URL)
    <a target="_blank" rel="noopener noreferrer" href="https://github.com/dotnet/runtime/issues/28204">https://github.com/dotnet/runtime/issues/28204</a>
    Motivations and driving principles behind the Utf8Char proposal

    <a target="_blank" rel="noopener noreferrer" href="https://github.com/dotnet/runtime/issues/933">https://github.com/dotnet/runtime/issues/933</a>
    The NuGet package generally follows the proposal in dotnet/corefxlab#2350, which
    is where most of the discussion has taken place. It's a bit aggravating that the
    discussion is split across so many different forums, I know. :(

        ceztko
        I noticed dotnet/corefxlab#2350 just got closed. Did the discussion moved
        somewhere else about more UTF8 first citizen support efforts?

        @ceztko The corefxlab repo was archived, so open issues were closed to
        support that effort. That thread also got so large that it was difficult
        to follow. @krwq is working on restructuring the conversation so that we
        can continue the discussion in a better forum.

        jlf
        Not clear where the discussion is continued...
        This URL just show some tags, one of them is "Future".
        <a target="_blank" rel="noopener noreferrer" href="https://github.com/orgs/dotnet/projects/7#card-33368432">https://github.com/orgs/dotnet/projects/7#card-33368432</a>


    <a target="_blank" rel="noopener noreferrer" href="https://github.com/dotnet/corefxlab/issues/2350">https://github.com/dotnet/corefxlab/issues/2350</a>
    Utf8String design discussion - last edited 14-Sep-19
    Tons of comments, with this conclusion:
    The discussion in this issue is too long and github has troubles rendering it.
    I think we should close this issue and start a new one in dotnet/runtime.


<hr><h2 id="Dafny_lang">Dafny lang</h2><hr>
<a target="_blank" rel="noopener noreferrer" href="https://corp.unicode.org/pipermail/unicode/2021-May/009434.html">https://corp.unicode.org/pipermail/unicode/2021-May/009434.html</a>
Dafny natively supports expressing statements about sets
and contract programming and a toy implementation turned out to be a fairly
rote translation of the Unicode spec.  Dafny is also transpilation focused,
so the primary interface must be highly functional and encoding neutral.


<hr><h2 id="Factor_lang">Factor lang</h2><hr>
<a target="_blank" rel="noopener noreferrer" href="http://docs.factorcode.org/content/article-unicode.html">http://docs.factorcode.org/content/article-unicode.html</a>

<a target="_blank" rel="noopener noreferrer" href="http://useless-factor.blogspot.fr/2007/02/doing-unicode-right-part-1.html">http://useless-factor.blogspot.fr/2007/02/doing-unicode-right-part-1.html</a>
JLF : bof...

<a target="_blank" rel="noopener noreferrer" href="http://useless-factor.blogspot.fr/2007/02/doing-unicode-right-part-2.html">http://useless-factor.blogspot.fr/2007/02/doing-unicode-right-part-2.html</a>

<a target="_blank" rel="noopener noreferrer" href="http://useless-factor.blogspot.fr/2007/08/unicode-implementers-guide-part-3.html">http://useless-factor.blogspot.fr/2007/08/unicode-implementers-guide-part-3.html</a>

<a target="_blank" rel="noopener noreferrer" href="http://useless-factor.blogspot.fr/2007/08/unicode-implementers-guide-part-4.html">http://useless-factor.blogspot.fr/2007/08/unicode-implementers-guide-part-4.html</a>
grapheme breaking

<a target="_blank" rel="noopener noreferrer" href="http://useless-factor.blogspot.fr/2007/08/r-597-rs-unicode-library-is-broken.html">http://useless-factor.blogspot.fr/2007/08/r-597-rs-unicode-library-is-broken.html</a>


<a target="_blank" rel="noopener noreferrer" href="http://useless-factor.blogspot.fr/2007/02/more-string-parsing.html">http://useless-factor.blogspot.fr/2007/02/more-string-parsing.html</a>
UTF-8/16 encoder/decoder

    I used a design pattern known as a sentinel, which helps me cross-cut pointcutting concerns
    by instantiating objects which encapsulate the state of the parser. I never mutate these,
    and the program is purely functional except for the use of make (which could trivially be
    changed into a less efficient map [ ] subset, sacrificing efficiency and some terseness
    but making it functional).

    TUPLE: new ;
    TUPLE: double val ;
    TUPLE: quad2 val ;
    TUPLE: quad3 val ;

    : bad-char CHAR: ? ;

    GENERIC: (utf16le) ( char state -- state )
    M: new (utf16le)
        drop &lt;double&gt; ;
    M: double (utf16le)
        over -3 shift BIN: 11011 = [
            over BIN: 100 bitand 0 =
            [ double-val swap BIN: 11 bitand 8 shift bitor &lt;quad2&gt; ]
            [ 2drop bad-char , &lt;new&gt; ] if
        ] [ double-val swap 8 shift bitor , &lt;new&gt; ] if ;
    M: quad2 (utf16le)
        quad2-val 10 shift bitor &lt;quad3&gt; ;
    M: quad3 (utf16le)
        over -2 shift BIN: 110111 = [
            swap BIN: 11 bitand 8 shift
            swap quad3-val bitor HEX: 10000 + , &lt;new&gt;
        ] [ 2drop bad-char , &lt;new&gt; ] if ;

    : utf16le ( state string -- state string )
        [ [ swap (utf16le) ] each ] { } make ;


<hr><h2 id="JavaScript_lang">JavaScript lang</h2><hr>
<a target="_blank" rel="noopener noreferrer" href="https://certitude.consulting/blog/en/invisible-backdoor/">https://certitude.consulting/blog/en/invisible-backdoor/</a>
THE INVISIBLE JAVASCRIPT BACKDOOR


<hr><h2 id="Julia_lang">Julia lang</h2><hr>
Remember: search in issues with "utf8proc in:title,body"


<a target="_blank" rel="noopener noreferrer" href="https://docs.julialang.org/en/v1/manual/strings/">https://docs.julialang.org/en/v1/manual/strings/</a>
    You can input any Unicode character in single quotes using \u followed by up to
    four hexadecimal digits or \U followed by up to eight hexadecimal digits
    (the longest valid value only requires six):

    julia&gt; '\u0'
    '\0': ASCII/Unicode U+0000 (category Cc: Other, control)

    julia&gt; '\u78'
    'x': ASCII/Unicode U+0078 (category Ll: Letter, lowercase)

    julia&gt; '\u2200'
    '‚àÄ': Unicode U+2200 (category Sm: Symbol, math)

    julia&gt; '\U10ffff'
    '\U10ffff': Unicode U+10FFFF (category Cn: Other, not assigned)

    julia&gt; s = "\u2200 x \u2203 y"
    "‚àÄ x ‚àÉ y"


<a target="_blank" rel="noopener noreferrer" href="https://juliapackages.com/p/strs">https://juliapackages.com/p/strs</a>
    This uses Swift-style \ escape sequences, such as \u{xxxx} for Unicode constants,
    instead of \uXXXX and \UXXXXXXXX, which have the advantage of not having to worry
    about some digit or letter A-F or a-f occurring after the last hex digit of the Unicode constant.

    It also means that $, a very common character for LaTeX strings or output of currencies,
     does not need to be in a string quoted as '$'

    It uses \(expr) for interpolation like Swift, instead of $name or $(expr), which
    also has the advantage of not having to worry about the next character in the
    string someday being allowed in a name.

    It allows for embedding Unicode characters using a variety of easy to remember
    names, instead of hex codes: \:emojiname: \&lt;latexname&gt; \N{unicodename} \&amp;htmlname;
    Examples of this are:
    f"\&lt;dagger&gt; \&amp;yen; \N{ACCOUNT OF} \:snake:", which returns the string: "‚Ä† ¬• ‚ÑÄ üêç "


<a target="_blank" rel="noopener noreferrer" href="https://discourse.julialang.org/t/stupid-question-on-unicode/27674/7">https://discourse.julialang.org/t/stupid-question-on-unicode/27674/7</a>
    Discussion about escape sequence


<a target="_blank" rel="noopener noreferrer" href="https://docs.julialang.org/en/v1/stdlib/Unicode/">https://docs.julialang.org/en/v1/stdlib/Unicode/</a>
Unicode.julia_chartransform(c::Union{Char,Integer})
Unicode.isassigned(c) -&gt; Bool
isequal_normalized(s1::AbstractString, s2::AbstractString; casefold=false, stripmark=false, chartransform=identity)
Unicode.normalize(s::AbstractString; keywords...)
    boolean keywords options (which all default to false except for compose)
        - compose=false: do not perform canonical composition
        - decompose=true: do canonical decomposition instead of canonical composition (compose=true is ignored if present)
        - compat=true: compatibility equivalents are canonicalized
        - casefold=true: perform Unicode case folding, e.g. for case-insensitive string comparison
        - newline2lf=true, newline2ls=true, or newline2ps=true: convert various newline sequences (LF, CRLF, CR, NEL) into a linefeed (LF), line-separation (LS), or paragraph-separation (PS) character, respectively
        - stripmark=true: strip diacritical marks (e.g. accents)
        - stripignore=true: strip Unicode's "default ignorable" characters (e.g. the soft hyphen or the left-to-right marker)
        - stripcc=true: strip control characters; horizontal tabs and form feeds are converted to spaces; newlines are also converted to spaces unless a newline-conversion flag was specified
        - rejectna=true: throw an error if unassigned code points are found
        - stable=true: enforce Unicode versioning stability (never introduce characters missing from earlier Unicode versions)
Unicode.normalize(s::AbstractString, normalform::Symbol)
    normalform can be :NFC, :NFD, :NFKC, or :NFKD.


utf8proc doesn't support language-sensitive case-folding
Julia, which uses utf8proc, has decided to remain locale-independent.
See <a target="_blank" rel="noopener noreferrer" href="https://github.com/JuliaLang/julia/issues/7848">https://github.com/JuliaLang/julia/issues/7848</a>


<a target="_blank" rel="noopener noreferrer" href="https://github.com/JuliaLang/julia/pull/42493">https://github.com/JuliaLang/julia/pull/42493</a>
This PR adds a function isequal_normalized to the Unicode stdlib to check whether
two strings are canonically equivalent (optionally casefolding and/or stripping combining marks).


<hr><h2 id="Kotlin_lang">Kotlin lang</h2><hr>
<a target="_blank" rel="noopener noreferrer" href="https://kotlinlang.org/api/latest/jvm/stdlib/kotlin.text/">https://kotlinlang.org/api/latest/jvm/stdlib/kotlin.text/</a>
<a target="_blank" rel="noopener noreferrer" href="https://github.com/JetBrains/kotlin/tree/master/libraries/stdlib/jvm/src/kotlin/text">https://github.com/JetBrains/kotlin/tree/master/libraries/stdlib/jvm/src/kotlin/text</a>


<hr><h2 id="Lisp_lang">Lisp lang</h2><hr>
14/09/2021
<a target="_blank" rel="noopener noreferrer" href="https://www.gnu.org/software/emacs/manual/html_node/elisp/Character-Properties.html">https://www.gnu.org/software/emacs/manual/html_node/elisp/Character-Properties.html</a>
    name
    Corresponds to the Name Unicode property. The value is a string consisting of upper-case Latin letters A to Z, digits, spaces, and hyphen ‚Äò-‚Äô characters. For unassigned codepoints, the value is nil.

    general-category
    Corresponds to the General_Category Unicode property. The value is a symbol whose name is a 2-letter abbreviation of the character‚Äôs classification. For unassigned codepoints, the value is Cn.

    canonical-combining-class
    Corresponds to the Canonical_Combining_Class Unicode property. The value is an integer. For unassigned codepoints, the value is zero.

    bidi-class
    Corresponds to the Unicode Bidi_Class property. The value is a symbol whose name is the Unicode directional type of the character. Emacs uses this property when it reorders bidirectional text for display (see Bidirectional Display). For unassigned codepoints, the value depends on the code blocks to which the codepoint belongs: most unassigned codepoints get the value of L (strong L), but some get values of AL (Arabic letter) or R (strong R).

    decomposition
    Corresponds to the Unicode properties Decomposition_Type and Decomposition_Value. The value is a list, whose first element may be a symbol representing a compatibility formatting tag, such as small18; the other elements are characters that give the compatibility decomposition sequence of this character. For characters that don‚Äôt have decomposition sequences, and for unassigned codepoints, the value is a list with a single member, the character itself.

    decimal-digit-value
    Corresponds to the Unicode Numeric_Value property for characters whose Numeric_Type is ‚ÄòDecimal‚Äô. The value is an integer, or nil if the character has no decimal digit value. For unassigned codepoints, the value is nil, which means NaN, or ‚Äúnot a number‚Äù.

    digit-value
    Corresponds to the Unicode Numeric_Value property for characters whose Numeric_Type is ‚ÄòDigit‚Äô. The value is an integer. Examples of such characters include compatibility subscript and superscript digits, for which the value is the corresponding number. For characters that don‚Äôt have any numeric value, and for unassigned codepoints, the value is nil, which means NaN.

    numeric-value
    Corresponds to the Unicode Numeric_Value property for characters whose Numeric_Type is ‚ÄòNumeric‚Äô. The value of this property is a number. Examples of characters that have this property include fractions, subscripts, superscripts, Roman numerals, currency numerators, and encircled numbers. For example, the value of this property for the character U+2155 VULGAR FRACTION ONE FIFTH is 0.2. For characters that don‚Äôt have any numeric value, and for unassigned codepoints, the value is nil, which means NaN.

    mirrored
    Corresponds to the Unicode Bidi_Mirrored property. The value of this property is a symbol, either Y or N. For unassigned codepoints, the value is N.

    mirroring
    Corresponds to the Unicode Bidi_Mirroring_Glyph property. The value of this property is a character whose glyph represents the mirror image of the character‚Äôs glyph, or nil if there‚Äôs no defined mirroring glyph. All the characters whose mirrored property is N have nil as their mirroring property; however, some characters whose mirrored property is Y also have nil for mirroring, because no appropriate characters exist with mirrored glyphs. Emacs uses this property to display mirror images of characters when appropriate (see Bidirectional Display). For unassigned codepoints, the value is nil.

    paired-bracket
    Corresponds to the Unicode Bidi_Paired_Bracket property. The value of this property is the codepoint of a character‚Äôs paired bracket, or nil if the character is not a bracket character. This establishes a mapping between characters that are treated as bracket pairs by the Unicode Bidirectional Algorithm; Emacs uses this property when it decides how to reorder for display parentheses, braces, and other similar characters (see Bidirectional Display).

    bracket-type
    Corresponds to the Unicode Bidi_Paired_Bracket_Type property. For characters whose paired-bracket property is non-nil, the value of this property is a symbol, either o (for opening bracket characters) or c (for closing bracket characters). For characters whose paired-bracket property is nil, the value is the symbol n (None). Like paired-bracket, this property is used for bidirectional display.

    old-name
    Corresponds to the Unicode Unicode_1_Name property. The value is a string. For unassigned codepoints, and characters that have no value for this property, the value is nil.

    iso-10646-comment
    Corresponds to the Unicode ISO_Comment property. The value is either a string or nil. For unassigned codepoints, the value is nil.

    uppercase
    Corresponds to the Unicode Simple_Uppercase_Mapping property. The value of this property is a single character. For unassigned codepoints, the value is nil, which means the character itself.

    lowercase
    Corresponds to the Unicode Simple_Lowercase_Mapping property. The value of this property is a single character. For unassigned codepoints, the value is nil, which means the character itself.

    titlecase
    Corresponds to the Unicode Simple_Titlecase_Mapping property. Title case is a special form of a character used when the first character of a word needs to be capitalized. The value of this property is a single character. For unassigned codepoints, the value is nil, which means the character itself.

    special-uppercase
    Corresponds to Unicode language- and context-independent special upper-casing rules. The value of this property is a string (which may be empty). For example mapping for U+00DF LATIN SMALL LETTER SHARP S is "SS". For characters with no special mapping, the value is nil which means uppercase property needs to be consulted instead.

    special-lowercase
    Corresponds to Unicode language- and context-independent special lower-casing rules. The value of this property is a string (which may be empty). For example mapping for U+0130 LATIN CAPITAL LETTER I WITH DOT ABOVE the value is "i\u0307" (i.e. 2-character string consisting of LATIN SMALL LETTER I followed by U+0307 COMBINING DOT ABOVE). For characters with no special mapping, the value is nil which means lowercase property needs to be consulted instead.

    special-titlecase
    Corresponds to Unicode unconditional special title-casing rules. The value of this property is a string (which may be empty). For example mapping for U+FB01 LATIN SMALL LIGATURE FI the value is "Fi". For characters with no special mapping, the value is nil which means titlecase property needs to be consulted instead.


<hr><h2 id="Mathematica_lang">Mathematica lang</h2><hr>
<a target="_blank" rel="noopener noreferrer" href="https://www.youtube.com/watch?v=yiwLBvirm7A">https://www.youtube.com/watch?v=yiwLBvirm7A</a>
Live CEOing Ep 426: Language Design in Wolfram Language [Unicode Characters &amp; WFR Suggestions]
At the begining, there are a few minutes about character properties.


<hr><h2 id="MOAR_VM_RAKU_lang">MOAR-VM RAKU lang</h2><hr>
29/05/2021
<a target="_blank" rel="noopener noreferrer" href="http://moarvm.com/releases.html">http://moarvm.com/releases.html</a>
    2017.07
        Greatly reduce the cases when string concatenation needs renormalization
        Use normalize_should_break to decide if concat needs normalization
        Rename should_break to MVM_unicode_normalize_should_break
        Fix memory leak in MVM_nfg_is_concat_stable
        If both last_a and first_b during concat are non-0 CCC, re-NFG
    --&gt; maybe to review : the last sentence seems to be an optimization of concatenation.
    2017.02
        Implement support for synthetic graphemes in MVM_unicode_string_compare
        Implement configurable collation_mode for MVM_unicode_string_compare
    2017.01
        Add a new unicmp_s op, which compares using the Unicode Collation Algorithm
        Add support for Grapheme_Cluster_Break=Prepend from Unicode 9.0
        Add a script to download the latest version of all of the Unicode data
    --&gt; should review this script
    2015.11
        NFG now uses Unicode Grapheme Cluster algorithm; "\r\n" is now one grapheme
    --&gt; ??? [later] ah, I had a bug! Was not analyzing an UTF-8 ASCII string... Now fixed:
        "0A0D"x~text~description= -- UTF-8 ASCII ( 2 graphemes, 2 codepoints, 2 bytes )
        "0D0A"x~text~description= -- UTF-8 ASCII ( 1 grapheme, 2 codepoints, 2 bytes )


29/05/2021
<a target="_blank" rel="noopener noreferrer" href="https://news.ycombinator.com/item?id=26591373">https://news.ycombinator.com/item?id=26591373</a>
String length functions for single emoji characters evaluate to greater than 1
--&gt; to check : MOAR VM really concatenate a 8bit string with a 32bit string using a string concatenation object ?

    You could do it the way Raku does. It's implementation defined. (Rakudo on MoarVM)
    The way MoarVM does it is that it does NFG, which is sort of like NFC except that it stores grapheme clusters as if they were negative codepoints.

    If a string is ASCII it uses an 8bit storage format, otherwise it uses a 32bit one.
    It also creates a tree of immutable string objects.
    If you do a substring operation it creates a substring object that points at an existing string object.
    If you combine two strings it creates a string concatenation object. Which is useful for combining an 8bit string with a 32bit one.
    All of that is completely opaque at the Raku level of course.

        my $str = "\c[FACE PALM, EMOJI MODIFIER FITZPATRICK TYPE-3, ZWJ, MALE SIGN, VARIATION SELECTOR-16]";

        say $str.chars;        # 1
        say $str.codes;        # 5
        say $str.encode('utf16').elems; # 7
        say $str.encode('utf16').bytes; # 14
        say $str.encode.elems; # 17
        say $str.encode.bytes; # 17
        say $str.codes * 4;    # 20
        #(utf32 encode/decode isn't implemented in MoarVM yet)

        say for $str.uninames;
        # FACE PALM
        # EMOJI MODIFIER FITZPATRICK TYPE-3
        # ZERO WIDTH JOINER
        # MALE SIGN
        # VARIATION SELECTOR-16
    The reason we have utf8-c8 encode/decode is because filenames, usernames, and passwords are not actually Unicode.
    (I have 4 files all named r√®sum√® in the same folder on my computer.)
    utf8-c8 uses the same synthetic codepoint system as grapheme clusters.


<a target="_blank" rel="noopener noreferrer" href="https://andrewshitov.com/2018/10/31/unicode-in-perl-6/">https://andrewshitov.com/2018/10/31/unicode-in-perl-6/</a>
Unicode in Raku

<hr><h2 id="Perl_lang__Perl_6_has_been_renamed_to_Raku_">Perl lang (Perl 6 has been renamed to Raku)</h2><hr>
<a target="_blank" rel="noopener noreferrer" href="https://swigunicode.wordpress.com/2021/10/18/example-post-3/">https://swigunicode.wordpress.com/2021/10/18/example-post-3/</a>
    SWIG and Perl: Unicode C Library
    Part 1. Small Intro to SWIG

    <a target="_blank" rel="noopener noreferrer" href="https://swigunicode.wordpress.com/2021/10/22/part-2-c-header-file/">https://swigunicode.wordpress.com/2021/10/22/part-2-c-header-file/</a>
    Part 2. C Header File

    <a target="_blank" rel="noopener noreferrer" href="https://swigunicode.wordpress.com/2021/10/24/part-3-c-source-file/">https://swigunicode.wordpress.com/2021/10/24/part-3-c-source-file/</a>
    Part 3. C Source File

    <a target="_blank" rel="noopener noreferrer" href="https://swigunicode.wordpress.com/2021/10/25/part-4-perl-source-file/">https://swigunicode.wordpress.com/2021/10/25/part-4-perl-source-file/</a>
    Part 4. Perl Source File

    <a target="_blank" rel="noopener noreferrer" href="https://swigunicode.wordpress.com/2021/10/26/part-5-build-and-run-scripts/">https://swigunicode.wordpress.com/2021/10/26/part-5-build-and-run-scripts/</a>
    Part 5. Build and Run Scripts

    <a target="_blank" rel="noopener noreferrer" href="https://swigunicode.wordpress.com/2021/10/27/part-6-swig-interface-file/">https://swigunicode.wordpress.com/2021/10/27/part-6-swig-interface-file/</a>
    Part 6. SWIG Interface File


<a target="_blank" rel="noopener noreferrer" href="https://lwn.net/Articles/667684/">https://lwn.net/Articles/667684/</a>
An article about NFG.
Unless one specifies otherwise, Perl 6 normalizes a text string to NFC when it's not NFG.


<hr><h2 id="PHP_lang">PHP lang</h2><hr>
<a target="_blank" rel="noopener noreferrer" href="https://github.com/nicolas-grekas/Patchwork-UTF8">https://github.com/nicolas-grekas/Patchwork-UTF8</a>
Extensive, portable and performant handling of UTF-8 and grapheme clusters for PHP


<hr><h2 id="Powershell_lang">Powershell lang</h2><hr>
<a target="_blank" rel="noopener noreferrer" href="https://stackoverflow.com/questions/57131654/using-utf-8-encoding-chcp-65001-in-command-prompt-windows-powershell-window">https://stackoverflow.com/questions/57131654/using-utf-8-encoding-chcp-65001-in-command-prompt-windows-powershell-window</a>
Using UTF-8 Encoding (CHCP 65001) in Command Prompt / Windows Powershell (Windows 10)
Describes how o set the system locale (language for non-Unicode programs) to UTF-8.
Optional reading: Why the Windows PowerShell ISE is a poor choice


<a target="_blank" rel="noopener noreferrer" href="https://stackoverflow.com/questions/49476326/displaying-unicode-in-powershell/49481797#49481797">https://stackoverflow.com/questions/49476326/displaying-unicode-in-powershell/49481797#49481797</a>
Displaying Unicode in Powershell


<hr><h2 id="Python_lang">Python lang</h2><hr>
10/08/2021
List of Python PEPS related to string.
<a target="_blank" rel="noopener noreferrer" href="https://www.python.org/dev/peps/">https://www.python.org/dev/peps/</a>
    Other Informational PEPs
        I	257	Docstring Conventions	Goodger, GvR
        I	287	reStructuredText Docstring Format	Goodger

    Accepted PEPs (accepted; may not be implemented yet)
        SA	597	Add optional EncodingWarning	Naoki
        SA	616	String methods to remove prefixes and suffixes	Sweeney
        SA	623	Remove wstr from Unicode	Naoki

    Open PEPs (under consideration)
        S	558	Defined semantics for locals()	Coghlan

    Finished PEPs (done, with a stable interface)
        SF	100	Python Unicode Integration	Lemburg
        SF	260	Simplify xrange()	GvR
        SF	261	Support for "wide" Unicode characters	Prescod
        SF	263	Defining Python Source Code Encodings	Lemburg, von L√∂wis
        SF	277	Unicode file name support for Windows NT	Hodgson
        SF	278	Universal Newline Support	Jansen
        SF	292	Simpler String Substitutions	Warsaw
        SF	331	Locale-Independent Float/String Conversions	Reis
        SF	393	Flexible String Representation	v. L√∂wis
        SF	414	Explicit Unicode Literal for Python 3.3	Ronacher, Coghlan
        SF	498	Literal String Interpolation	Smith
        SF	515	Underscores in Numeric Literals	Brandl, Storchaka
        SF	528	Change Windows console encoding to UTF-8	Dower
        SF	529	Change Windows filesystem encoding to UTF-8	Dower
        SF	538	Coercing the legacy C locale to a UTF-8 based locale	Coghlan
        SF	540	Add a new UTF-8 Mode	Stinner
        SF	624	Remove Py_UNICODE encoder APIs	Naoki
        SF	3101	Advanced String Formatting	Talin
        SF	3112	Bytes literals in Python 3000	Orendorff
        SF	3120	Using UTF-8 as the default source encoding	von L√∂wis
        SF	3127	Integer Literal Support and Syntax	Maupin
        SF	3131	Supporting Non-ASCII Identifiers	von L√∂wis
        SF	3137	Immutable Bytes and Mutable Buffer	GvR
        SF	3138	String representation in Python 3000	Ishimoto

    Deferred PEPs (postponed pending further research or updates)
        SD	501	General purpose string interpolation	Coghlan
        SD	536	Final Grammar for Literal String Interpolation	Angerer

    Abandoned, Withdrawn, and Rejected PEPs
        SS	215	String Interpolation	Yee
        IR	216	Docstring Format	Zadka
        SR	224	Attribute Docstrings	Lemburg
        SR	256	Docstring Processing System Framework	Goodger
        SR	295	Interpretation of multiline string constants	Koltsov
        SR	332	Byte vectors and String/Unicode Unification	Montanaro
        SR	349	Allow str() to return unicode strings	Schemenauer
        IR	502	String Interpolation - Extended Discussion	Miller
        SR	3126	Remove Implicit String Concatenation	Jewett, Hettinger


15/07/2021
review
<a target="_blank" rel="noopener noreferrer" href="https://docs.python.org/3/howto/unicode.html">https://docs.python.org/3/howto/unicode.html</a>

    Escape sequences in string literals
        "\N{GREEK CAPITAL LETTER DELTA}"        # Using the character name  '\u0394'
        "\u0394"                                # Using a 16-bit hex value  '\u0394'
        "\U00000394"                            # Using a 32-bit hex value  '\u0394'

    One can create a string using the decode() method of bytes.
    This method takes an encoding argument, such as UTF-8, and optionally an errors argument.
    The errors argument specifies the response when the input string can‚Äôt be converted
    according to the encoding‚Äôs rules. Legal values for this argument are
        'strict'            (raise a UnicodeDecodeError exception),
        'replace'           (use U+FFFD, REPLACEMENT CHARACTER),
        'ignore'            (just leave the character out of the Unicode result),
        'backslashreplace'  (inserts a \xNN escape sequence).
    Examples:
        b'\x80abc'.decode("utf-8", "strict")                # UnicodeDecodeError: 'utf-8' codec can't decode byte 0x80 in position 0
        b'\x80abc'.decode("utf-8", "replace")               # '\ufffdabc'
        b'\x80abc'.decode("utf-8", "backslashreplace")      # '\\x80abc'
        b'\x80abc'.decode("utf-8", "ignore")                # 'abc'

    Encodings are specified as strings containing the encoding‚Äôs name.
    Python comes with roughly 100 different encodings:
        <a target="_blank" rel="noopener noreferrer" href="https://docs.python.org/3/library/codecs.html#standard-encodings">https://docs.python.org/3/library/codecs.html#standard-encodings</a>

    One-character Unicode strings can also be created with the chr() built-in function,
    which takes integers and returns a Unicode string of length 1 that contains the corresponding code point:
        chr(57344)      # '\ue000'
    The reverse operation is the built-in ord() function that takes a one-character Unicode string and returns the code point value:
        ord('\ue000')   # 57344

    The opposite method of bytes.decode() is str.encode(), which returns a bytes representation of the Unicode string, encoded in the requested encoding.
    The errors parameter is the same as the parameter of the decode() method but supports a few more possible handlers.
        'strict'            (raise a UnicodeDecodeError exception),
        'replace'           inserts a question mark instead of the unencodable character,
        'ignore'            (just leave the character out of the Unicode result),
        'backslashreplace'  (inserts a \uNNNN escape sequence)
        'xmlcharrefreplace' (inserts an XML character reference),
        'namereplace'       (inserts a \N{...} escape sequence).

    Unicode code points can be written using the \u escape sequence, which is
    followed by four hex digits giving the code point. The \U escape sequence
    is similar, but expects eight hex digits, not four
        &gt;&gt;&gt; s = "a\xac\u1234\u20ac\U00008000"
        ... #     ^^^^ two-digit hex escape
        ... #         ^^^^^^ four-digit Unicode escape
        ... #                     ^^^^^^^^^^ eight-digit Unicode escape
        &gt;&gt;&gt; [ord(c) for c in s]
        [97, 172, 4660, 8364, 32768]

    Python supports writing source code in UTF-8 by default, but you can use almost any encoding if you declare the encoding being used. This is done by including a special comment as either the first or second line of the source file:
        #!/usr/bin/env python
        # -*- coding: latin-1 -*-
        u = 'abcd√©'
    <a target="_blank" rel="noopener noreferrer" href="https://www.python.org/dev/peps/pep-0263/">https://www.python.org/dev/peps/pep-0263/</a>
    PEP 263 -- Defining Python Source Code Encodings

    Comparing Strings
    The casefold() string method converts a string to a case-insensitive
    form following an algorithm described by the Unicode Standard. This
    algorithm has special handling for characters such as the German letter ‚Äò√ü‚Äô
    (code point U+00DF), which becomes the pair of lowercase letters ‚Äòss‚Äô.
        &gt;&gt;&gt; street = 'G√ºrzenichstra√üe'
        &gt;&gt;&gt; street.casefold()
        'g√ºrzenichstrasse'
    The unicodedata module‚Äôs normalize() function converts strings to one of
    several normal forms: ‚ÄòNFC‚Äô, ‚ÄòNFKC‚Äô, ‚ÄòNFD‚Äô, and ‚ÄòNFKD‚Äô.
        def compare_strs(s1, s2):
            def NFD(s):
                return unicodedata.normalize('NFD', s)
            return NFD(s1) == NFD(s2)
    The Unicode Standard also specifies how to do caseless comparisons:
        def compare_caseless(s1, s2):
            def NFD(s):
                return unicodedata.normalize('NFD', s)
            return NFD(NFD(s1).casefold()) == NFD(NFD(s2).casefold())
    Why is NFD() invoked twice? Because there are a few characters that make
    casefold() return a non-normalized string, so the result needs to be
    normalized again. See section 3.13 of the Unicode Standard

    <a target="_blank" rel="noopener noreferrer" href="https://docs.python.org/3/library/unicodedata.html">https://docs.python.org/3/library/unicodedata.html</a>
        unicodedata.lookup(name)
            Look up character by name.
            If a character with the given name is found, return the corresponding character.
            If not found, KeyError is raised.
            Changed in version 3.3: Support for name aliases 1 and named sequences 2 has been added.
        unicodedata.name(chr[, default])
            Returns the name assigned to the character chr as a string.
        unicodedata.decimal(chr[, default])
            Returns the decimal value assigned to the character chr as integer.
        unicodedata.digit(chr[, default])
            Returns the digit value assigned to the character chr as integer.
        unicodedata.numeric(chr[, default])
            Returns the numeric value assigned to the character chr as float.
        unicodedata.category(chr)
            Returns the general category assigned to the character chr as string.
        unicodedata.bidirectional(chr)
            Returns the bidirectional class assigned to the character chr as string.
        unicodedata.combining(chr)
            Returns the canonical combining class assigned to the character chr as integer.
            Returns 0 if no combining class is defined.
        unicodedata.east_asian_width(chr)
            Returns the east asian width assigned to the character chr as string.
        unicodedata.mirrored(chr)
            Returns the mirrored property assigned to the character chr as integer.
            Returns 1 if the character has been identified as a ‚Äúmirrored‚Äù character in bidirectional text, 0 otherwise.
        unicodedata.decomposition(chr)
            Returns the character decomposition mapping assigned to the character chr as string.
            An empty string is returned in case no such mapping is defined.
        unicodedata.normalize(form, unistr)
            Return the normal form form for the Unicode string unistr.
            Valid values for form are ‚ÄòNFC‚Äô, ‚ÄòNFKC‚Äô, ‚ÄòNFD‚Äô, and ‚ÄòNFKD‚Äô.
        unicodedata.is_normalized(form, unistr)
            Return whether the Unicode string unistr is in the normal form form.
            Valid values for form are ‚ÄòNFC‚Äô, ‚ÄòNFKC‚Äô, ‚ÄòNFD‚Äô, and ‚ÄòNFKD‚Äô.
        unicodedata.unidata_version
            The version of the Unicode database used in this module.
        unicodedata.ucd_3_2_0
            This is an object that has the same methods as the entire module,
            but uses the Unicode database version 3.2 instead

    <a target="_blank" rel="noopener noreferrer" href="https://www.python.org/dev/peps/pep-0393/">https://www.python.org/dev/peps/pep-0393/</a>
    PEP 393 -- Flexible String Representation
        When creating new strings, it was common in Python to start of with a
        heuristical buffer size, and then grow or shrink if the heuristics failed.
        With this PEP, this is now less practical, as you need not only a heuristics
        for the length of the string, but also for the maximum character.

        In order to avoid heuristics, you need to make two passes over the input:
        once to determine the output length, and the maximum character; then
        allocate the target string with PyUnicode_New and iterate over the input
        a second time to produce the final output. While this may sound expensive,
        it could actually be cheaper than having to copy the result again as in
        the following approach.

        If you take the heuristical route, avoid allocating a string meant to be
        resized, as resizing strings won't work for their canonical representation.
        Instead, allocate a separate buffer to collect the characters, and then
        construct a unicode object from that using PyUnicode_FromKindAndData.
        One option is to use Py_UCS4 as the buffer element, assuming for the worst
        case in character ordinals. This will allow for pointer arithmetics, but
         may require a lot of memory. Alternatively, start with a 1-byte buffer,
         and increase the element size as you encounter larger characters.
         In any case, PyUnicode_FromKindAndData will scan over the buffer to
         verify the maximum character.


15/07/2021
<a target="_blank" rel="noopener noreferrer" href="https://docs.python.org/3/library/codecs.html">https://docs.python.org/3/library/codecs.html</a>
Codec registry and base classes
Most standard codecs are text encodings, which encode text to bytes, but there
are also codecs provided that encode text to text, and bytes to bytes.
errors string argument:
    strict
    ignore
    replace
    xmlcharrefreplace
    backslashreplace
    namereplace
    surrogateescape
    surrogatepass


15/07/2021
<a target="_blank" rel="noopener noreferrer" href="https://discourse.julialang.org/t/a-python-rant-about-types/43294/22">https://discourse.julialang.org/t/a-python-rant-about-types/43294/22</a>
A Python rant about types
jlf: the main discussion is about invalid string data.
Stefan Karpinski describes the Julia strings:
    1. You can read and write any data, valid or not.
    2. It is interpreted as UTF-8 where possible and as invalid characters otherwise.
    3. You can simply check if strings or chars are valid UTF-8 or not.
    4. You can work with individual characters easily, even invalid ones.
    5. You can losslessly read and write any string data, valid or not, as strings or chars.
    6. You only get an error when you try to ask for the code point of an invalid char.
    Most Julia code that works with strings is automatically robust with respect to
    invalid UTF-8 data. Only code that needs to look at the code points of individual
    characters will fail on invalid data; in order to do that robustly, you simply
    need to check if the character is valid before taking its code point and handle
    that appropriately.
jlf: I think that all the Julia methods working at character level will raise an error,
not just when looking at the code point.
jlf: Stefan Karpinski explains why Python design is problematic.
Python 3 has to be able to represent any input string in terms of code points.
Needing to turn every string into a fixed-width sequence of code points puts them
in a tough position with respect to invalid strings where there is simply no
corresponding sequence of code points.


17/07/2021
<a target="_blank" rel="noopener noreferrer" href="https://groups.google.com/g/python-ideas/c/wStIS1_NVJQ">https://groups.google.com/g/python-ideas/c/wStIS1_NVJQ</a>
Fix default encodings on Windows
jlf: did not read in details, too long, too many feedbacks.
Maybe some comments are interesting, so I save this URL.


<a target="_blank" rel="noopener noreferrer" href="https://djangocas.dev/blog/python-unicode-string-lowercase-casefold-caseless-match/">https://djangocas.dev/blog/python-unicode-string-lowercase-casefold-caseless-match/</a>
Interesting infos about caseless matching


<hr><h2 id="Rexx_lang">Rexx lang</h2><hr>
11/08/2021
<a target="_blank" rel="noopener noreferrer" href="http://nokix.sourceforge.net/help/learn_rexx/funcs5.htm#VALUEIN">http://nokix.sourceforge.net/help/learn_rexx/funcs5.htm#VALUEIN</a>
Reads in a numeric value from a binary (ie, non-text) file.
value = VALUEIN(stream, position, length, options)
    Args
        stream is the name of the stream.
        It can include the full path to the stream (ie, any drive and directory names).
        If omitted, the default is to read from STDIN.

        position specifies at what character position (within the stream) to start
        reading from, where 1 means to start reading at the very first character
        in the stream. If omitted, the default is to resume reading at where a
        previous call to CHARIN() or VALUEIN() left off (ie, where you current
        read character position is).

        length is a 1 to read in the next binary byte (ie, 8-bit value), a 2 to
        read in the next binary short (ie, 16-bit value), or a 4 to read in the
        next binary long (ie, 32-bit value). If length is omitted, VALUEIN() defaults to reading a byte.

        options can be any of the following:
            M	The value is stored (in the stream) in Motorola (big endian) byte order,
                rather than Intel (little endian) byte order.
                The effects only long and short values.
            H	Read in the value as hexadecimal (rather than the default of base 10,
                or decimal, which is the base that REXX uses to express numbers).
                The value can later be converted with X2D().
            B	Read in the value as binary (base 2).
            -	The value is signed (as opposed to unsigned).
            V	stream is the actual data string from which to extract a value.
                You can now replace calls to SUBSTR and C2D with a single, faster call to VALUEIN.
            If omitted, options defaults to none of the above.
    Returns
        The value, if successful.
        If an error, an empty string is returned (unless the NOTREADY condition
        is trapped via CALL method. Then, a '0' is returned).

<a target="_blank" rel="noopener noreferrer" href="http://nokix.sourceforge.net/help/learn_rexx/funcs5.htm#VALUEOUT">http://nokix.sourceforge.net/help/learn_rexx/funcs5.htm#VALUEOUT</a>
Write out numeric values to a binary (ie, non-text) file (ie, in non-text format).
result = VALUEOUT(stream, values, position, size, options)
    Args
        stream is the name of the stream.
        It can include the full path to the stream (ie, any drive and directory names).
        If omitted, the default is to write to STDOUT (typically, display the data in the console window).

        position specifies at what character position (within the stream) to start writing the data,
        where 1 means to start writing at the very first character in the stream.
        If omitted, the default is to resume writing at where a previous call to
        CHAROUT() or VALUEOUT() left off (or where the "write character pointer" was set via STREAM's SEEK).

        values are the numeric values (ie, data) to write out.
        Each value is separated by one space.

        size is a 1 if each value is to be written as a byte (ie, 8-bit value),
        2 if each value is to be written as a short (16-bit value),
        or 4 if each value is to be written as a long (32-bit value). If omitted, size defaults to 1.

        options can be any of the following:
            M	Write out the values in Motorola (big endian) byte order,
                rather than Intel (little endian) byte order. The effects only long and short values.
            H	The values you supplied are specified in hexadecimal.
            B	The values you supplied are specified in binary (base 2).
            V	stream is the name of a variable, and the data will be overlaid
                onto that variable's value. You can now replace calls to D2C and
                OVERLAY with a single, faster call to VALUEOUT, especially when
                a variable has a large amount of non-text data.
            If omitted, options defaults to none of the above.
    Returns
        0 if the string was written out successfully.
        If an error, VALUEOUT() returns non-zero.


<a target="_blank" rel="noopener noreferrer" href="http://www.dg77.net/tekno/manuel/rexxendian.htm">http://www.dg77.net/tekno/manuel/rexxendian.htm</a>
Test de l‚Äôendianit√©
    /* Verifie l'endianit√© / check endiannity          */
    /* Pour traitement d'information encodees en UTF-8 */
    /* Adapter si on utilise un autre encodage         */
    CALL CONV8_16 ' '
    IF c2x(sortie) = '2000' THEN DO
        endian = 'LE' /* little endian  */
        blanx = '2000'
        END
    ELSE DO
        endian = 'BE' /* big endian  */
        blanx = '0020'
        END
    return endian blanx
    /* ********************************************************************** */
    /*           Conversion UTF-8 -&gt; UNICODE                                  */
    CONV8_16:
    parse arg entree
    sortie = ''
    ZONESORTIE.='NUL'; ZONESORTIE.0=0
    err = systounicode(entree, 'UTF8', , ZONESORTIE.)
    if err == 0 then sortie = ZONESORTIE.!TEXT
      else say 'probleme car., code ' err
    return


<a target="_blank" rel="noopener noreferrer" href="http://www.dg77.net/tekno/xhtml/codage.htm">http://www.dg77.net/tekno/xhtml/codage.htm</a>
Le codage des caract√®res
To read, some infos about the code pages could be useful.


Regina doc
    EXPORT(address, [string], [length] [,pad]) - (AREXX)
        Copies data from the (optional) string into a previously-allocated memory area, which must be
        specified as a 4-byte address. The length parameter specifies the maximum number of characters to
        be copied; the default is the length of the string. If the specified length is longer than the string, the
        remaining area is filled with the pad character or nulls('00'x). The returned value is the number
        of characters copied.
        Caution is advised in using this function. Any area of memory can be overwritten,possibly
        causing a system crash.
        See also STORAGE() and IMPORT().
        Note that the address specified is subject to a machine's endianess.
        EXPORT('0004 0000'x,'The answer') '10'

    IMPORT(address [,length]) - (AREXX)
        Creates a string by copying data from the specified 4-byte address. If the length parameter is not
        supplied,the copy terminates when a null byte is found.
        See also EXPORT()
        Note that the address specified is subject to a machine's endianess.
        IMPORT('0004 0000'x,10) 'The answer' /* maybe */


<hr><h2 id="Rust_lang">Rust lang</h2><hr>
Seen in a comment here :  <a target="_blank" rel="noopener noreferrer" href="https://bugs.swift.org/browse/SR-7602">https://bugs.swift.org/browse/SR-7602</a>

    For reference, I think [Rust's model]( <a target="_blank" rel="noopener noreferrer" href="https://doc.rust-lang.org/std/string/struct.String.html">https://doc.rust-lang.org/std/string/struct.String.html</a> ) is pretty good:

    `from_utf8` produces an error explaining why the code units were invalid
    `from_utf8_lossy` replaces encoding errors with U+FFFD
    `from_utf8_unchecked` which takes the bytes, but if there's an encoding error, then memory safety has been violated

    I'm not entirely sure if accepting invalid bytes requires voiding memory safety (assuming bounds checking always happens), but it is totally a security hazard if used improperly.
    We may want to be very cautious about if/how we expose it.

    I think that trying to do read-time validation is dubious for UTF-16, and totally bananas for UTF-8.


17/07/2021
<a target="_blank" rel="noopener noreferrer" href="https://www.generacodice.com/en/articolo/120763/Unicode+Support+in+Various+Programming+Languages">https://www.generacodice.com/en/articolo/120763/Unicode+Support+in+Various+Programming+Languages</a>
jlf: I learned something: OsStr/OsString
    Rust's strings (std::String and &amp;str) are always valid UTF-8, and do not use null
    terminators, and as a result can not be indexed as an array, like they can be in C/C++, etc.
    They can be sliced somewhat like Go using .get since 1.20, with the caveat that
    it will fail if you try slicing the middle of a code point.

    Rust also has OsStr/OsString for interacting with the Host OS.
    It's byte array on Unix (containing any sequence of bytes).
    On windows it's WTF-8 (A super-set of UTF-8 that handles the improperly
    formed Unicode strings that are allowed in Windows and Javascript),
    &amp;str and String can be freely converted to OsStr or OsString, but require
    checks to covert the other way. Either by Failing on invalid unicode, or
    replacing with the Unicode replacement char. (There is also Path/PathBuf,
    which are just wrappers around OsStr/OsString).

    There is also the CStr and CString types, which represent Null terminated C
    strings, like OsStr on Unix they can contain arbitrary bytes.

    Rust doesn't directly support UTF-16. But can convert OsStr to UCS-2 on windows.


22/07/2021
<a target="_blank" rel="noopener noreferrer" href="https://lib.rs/crates/">https://lib.rs/crates/</a>
STFU-8: Sorta Text Format in UTF-8
STFU-8 is a hacky text encoding/decoding protocol for data that might be not
quite UTF-8 but is still mostly UTF-8.
Its primary purpose is to be able to allow a human to visualize and edit "data"
that is mostly (or fully) visible UTF-8 text. It encodes all non visible or non
UTF-8 compliant bytes as longform text (i.e. ESC becomes the full string r"\x1B").
It can also encode/decode ill-formed UTF-16.


28/07/2021
<a target="_blank" rel="noopener noreferrer" href="https://fasterthanli.me/articles/working-with-strings-in-rust">https://fasterthanli.me/articles/working-with-strings-in-rust</a>


07/11/2021
<a target="_blank" rel="noopener noreferrer" href="https://blog.rust-lang.org/2021/11/01/cve-2021-42574.html">https://blog.rust-lang.org/2021/11/01/cve-2021-42574.html</a>
security concern affecting source code containing "bidirectional override" Unicode codepoints


10/03/2022
<a target="_blank" rel="noopener noreferrer" href="https://rust-lang.github.io/rfcs/2457-non-ascii-idents.html">https://rust-lang.github.io/rfcs/2457-non-ascii-idents.html</a>
Allow non-ASCII letters (such as accented characters, Cyrillic, Greek, Kanji, etc.) in Rust identifiers.


<hr><h2 id="Swift_lang">Swift lang</h2><hr>
03/08/2021
<a target="_blank" rel="noopener noreferrer" href="https://swiftdoc.org/v5.1/type/string/">https://swiftdoc.org/v5.1/type/string/</a>
Auto-generated documentation for Swift.
A Unicode string value that is a collection of characters.


15/07/2017
String Processing For Swift 4
<a target="_blank" rel="noopener noreferrer" href="https://github.com/apple/swift/blob/master/docs/StringManifesto.md">https://github.com/apple/swift/blob/master/docs/StringManifesto.md</a>


<a target="_blank" rel="noopener noreferrer" href="https://swift.org/blog/utf8-string/">https://swift.org/blog/utf8-string/</a>
Swift 5 switches the preferred encoding of strings from UTF-16 to UTF-8 while preserving efficient Objective-C-interoperability.


<a target="_blank" rel="noopener noreferrer" href="https://bugs.swift.org/browse/SR-7602">https://bugs.swift.org/browse/SR-7602</a>
UTF8 should be (one of) the fastest String encoding(s)


<a target="_blank" rel="noopener noreferrer" href="https://github.com/apple/swift/blob/7e68e8f4a3cb1173e909dc22a3490c05e43fa592/stdlib/public/core/StringObject.swift">https://github.com/apple/swift/blob/7e68e8f4a3cb1173e909dc22a3490c05e43fa592/stdlib/public/core/StringObject.swift</a>
swift/stdlib/public/core/StringObject.swift


milseman Michael Ilseman added a comment - 5 Nov 2018 3:44 PM
    It's now the fastest encoding.
    <a target="_blank" rel="noopener noreferrer" href="https://forums.swift.org/t/string-s-abi-and-utf-8/17676/1">https://forums.swift.org/t/string-s-abi-and-utf-8/17676/1</a>
    <a target="_blank" rel="noopener noreferrer" href="https://github.com/apple/swift/pull/20315">https://github.com/apple/swift/pull/20315</a>


13/06/2021
<a target="_blank" rel="noopener noreferrer" href="https://github.com/apple/swift-evolution/blob/master/proposals/0211-unicode-scalar-properties.md">https://github.com/apple/swift-evolution/blob/master/proposals/0211-unicode-scalar-properties.md</a>
Add Unicode Properties to Unicode.Scalar
    Issues Linking with ICU
    The Swift standard library uses the system's ICU libraries to implement its Unicode support.
    A third-party developer may expect that they could also link their application directly to the system ICU
    to access the functionality that they need, but this proves problematic on both Apple and Linux platforms.
    Apple
        On Apple operating systems, libicucore.dylib is built with function renaming disabled
        (function names lack the _NN version number suffix). This makes it fairly straightforward to import the C APIs
        and call them from Swift without worrying about which version the operating system is using.
        Unfortunately, libicucore.dylib is considered to be private API for submissions to the App Store,
        so applications doing this will be rejected. Instead, users must built their own copy of ICU from source
        and link that into their applications. This is significant overhead.
    Linux
        On Linux, system ICU libraries are built with function renaming enabled (the default),
        so function names have the _NN version number suffix. Function renaming makes it more difficult
        to use these APIs from Swift; even though the C header files contain #defines that map function names
        like u_foo_59 to u_foo, these #defines are not imported into Swift‚Äîonly the suffixed function names are available.
        This means that Swift bindings would be fixed to a specific version of the library without some other intermediary layer.
        Again, this is significant overhead.
    extension Unicode.Scalar.Properties {
      public var isAlphabetic: Bool { get }    // Alphabetic
      public var isASCIIHexDigit: Bool { get }    // ASCII_Hex_Digit
      public var isBidiControl: Bool { get }    // Bidi_Control
      public var isBidiMirrored: Bool { get }    // Bidi_Mirrored
      public var isDash: Bool { get }    // Dash
      public var isDefaultIgnorableCodePoint: Bool { get }    // Default_Ignorable_Code_Point
      public var isDeprecated: Bool { get }    // Deprecated
      public var isDiacritic: Bool { get }    // Diacritic
      public var isExtender: Bool { get }    // Extender
      public var isFullCompositionExclusion: Bool { get }    // Full_Composition_Exclusion
      public var isGraphemeBase: Bool { get }    // Grapheme_Base
      public var isGraphemeExtend: Bool { get }    // Grapheme_Extend
      public var isHexDigit: Bool { get }    // Hex_Digit
      public var isIDContinue: Bool { get }    // ID_Continue
      public var isIDStart: Bool { get }    // ID_Start
      public var isIdeographic: Bool { get }    // Ideographic
      public var isIDSBinaryOperator: Bool { get }    // IDS_Binary_Operator
      public var isIDSTrinaryOperator: Bool { get }    // IDS_Trinary_Operator
      public var isJoinControl: Bool { get }    // Join_Control
      public var isLogicalOrderException: Bool { get }    // Logical_Order_Exception
      public var isLowercase: Bool { get }    // Lowercase
      public var isMath: Bool { get }    // Math
      public var isNoncharacterCodePoint: Bool { get }    // Noncharacter_Code_Point
      public var isQuotationMark: Bool { get }    // Quotation_Mark
      public var isRadical: Bool { get }    // Radical
      public var isSoftDotted: Bool { get }    // Soft_Dotted
      public var isTerminalPunctuation: Bool { get }    // Terminal_Punctuation
      public var isUnifiedIdeograph: Bool { get }    // Unified_Ideograph
      public var isUppercase: Bool { get }    // Uppercase
      public var isWhitespace: Bool { get }    // Whitespace
      public var isXIDContinue: Bool { get }    // XID_Continue
      public var isXIDStart: Bool { get }    // XID_Start
      public var isCaseSensitive: Bool { get }    // Case_Sensitive
      public var isSentenceTerminal: Bool { get }    // Sentence_Terminal (S_Term)
      public var isVariationSelector: Bool { get }    // Variation_Selector
      public var isNFDInert: Bool { get }    // NFD_Inert
      public var isNFKDInert: Bool { get }    // NFKD_Inert
      public var isNFCInert: Bool { get }    // NFC_Inert
      public var isNFKCInert: Bool { get }    // NFKC_Inert
      public var isSegmentStarter: Bool { get }    // Segment_Starter
      public var isPatternSyntax: Bool { get }    // Pattern_Syntax
      public var isPatternWhitespace: Bool { get }    // Pattern_White_Space
      public var isCased: Bool { get }    // Cased
      public var isCaseIgnorable: Bool { get }    // Case_Ignorable
      public var changesWhenLowercased: Bool { get }    // Changes_When_Lowercased
      public var changesWhenUppercased: Bool { get }    // Changes_When_Uppercased
      public var changesWhenTitlecased: Bool { get }    // Changes_When_Titlecased
      public var changesWhenCaseFolded: Bool { get }    // Changes_When_Casefolded
      public var changesWhenCaseMapped: Bool { get }    // Changes_When_Casemapped
      public var changesWhenNFKCCaseFolded: Bool { get }    // Changes_When_NFKC_Casefolded
      public var isEmoji: Bool { get }    // Emoji
      public var isEmojiPresentation: Bool { get }    // Emoji_Presentation
      public var isEmojiModifier: Bool { get }    // Emoji_Modifier
      public var isEmojiModifierBase: Bool { get }    // Emoji_Modifier_Base
    }
    extension Unicode.Scalar.Properties {

      // Implemented in terms of ICU's `u_isdefined`.
      public var isDefined: Bool { get }
    }
    Case Mappings
    The properties below provide full case mappings for scalars. Since a handful of mappings result in multiple scalars (e.g., "√ü" uppercases to "SS"), these properties are String-valued, not Unicode.Scalar.
    extension Unicode.Scalar.Properties {

      public var lowercaseMapping: String { get }  // u_strToLower
      public var titlecaseMapping: String { get }  // u_strToTitle
      public var uppercaseMapping: String { get }  // u_strToUpper
    }
Identification and Classification
    extension Unicode.Scalar.Properties {

      /// Corresponds to the `Age` Unicode property, when a code point was first
      /// defined.
      public var age: Unicode.Version? { get }

      /// Corresponds to the `Name` Unicode property.
      public var name: String? { get }

      /// Corresponds to the `Name_Alias` Unicode property.
      public var nameAlias: String? { get }

      /// Corresponds to the `General_Category` Unicode property.
      public var generalCategory: Unicode.GeneralCategory { get }

      /// Corresponds to the `Canonical_Combining_Class` Unicode property.
      public var canonicalCombiningClass: Unicode.CanonicalCombiningClass { get }
    }

    extension Unicode {

      /// Represents the version of Unicode in which a scalar was introduced.
      public typealias Version = (major: Int, minor: Int)

      /// General categories returned by
      /// `Unicode.Scalar.Properties.generalCategory`. Listed along with their
      /// two-letter code.
      public enum GeneralCategory {
        case uppercaseLetter  // Lu
        case lowercaseLetter  // Ll
        case titlecaseLetter  // Lt
        case modifierLetter  // Lm
        case otherLetter  // Lo

        case nonspacingMark  // Mn
        case spacingMark  // Mc
        case enclosingMark  // Me

        case decimalNumber  // Nd
        case letterlikeNumber  // Nl
        case otherNumber  // No

        case connectorPunctuation  //Pc
        case dashPunctuation  // Pd
        case openPunctuation  // Ps
        case closePunctuation  // Pe
        case initialPunctuation  // Pi
        case finalPunctuation  // Pf
        case otherPunctuation  // Po

        case mathSymbol  // Sm
        case currencySymbol  // Sc
        case modifierSymbol  // Sk
        case otherSymbol  // So

        case spaceSeparator  // Zs
        case lineSeparator  // Zl
        case paragraphSeparator  // Zp

        case control  // Cc
        case format  // Cf
        case surrogate  // Cs
        case privateUse  // Co
        case unassigned  // Cn
      }

      public struct CanonicalCombiningClass:
        Comparable, Hashable, RawRepresentable
      {
        public static let notReordered = CanonicalCombiningClass(rawValue: 0)
        public static let overlay = CanonicalCombiningClass(rawValue: 1)
        public static let nukta = CanonicalCombiningClass(rawValue: 7)
        public static let kanaVoicing = CanonicalCombiningClass(rawValue: 8)
        public static let virama = CanonicalCombiningClass(rawValue: 9)
        public static let attachedBelowLeft = CanonicalCombiningClass(rawValue: 200)
        public static let attachedBelow = CanonicalCombiningClass(rawValue: 202)
        public static let attachedAbove = CanonicalCombiningClass(rawValue: 214)
        public static let attachedAboveRight = CanonicalCombiningClass(rawValue: 216)
        public static let belowLeft = CanonicalCombiningClass(rawValue: 218)
        public static let below = CanonicalCombiningClass(rawValue: 220)
        public static let belowRight = CanonicalCombiningClass(rawValue: 222)
        public static let left = CanonicalCombiningClass(rawValue: 224)
        public static let right = CanonicalCombiningClass(rawValue: 226)
        public static let aboveLeft = CanonicalCombiningClass(rawValue: 228)
        public static let above = CanonicalCombiningClass(rawValue: 230)
        public static let aboveRight = CanonicalCombiningClass(rawValue: 232)
        public static let doubleBelow = CanonicalCombiningClass(rawValue: 233)
        public static let doubleAbove = CanonicalCombiningClass(rawValue: 234)
        public static let iotaSubscript = CanonicalCombiningClass(rawValue: 240)

        public let rawValue: UInt8

        public init(rawValue: UInt8)
      }
    }
    Numerics
    Many Unicode scalars have associated numeric values.
    These are not only the common digits zero through nine, but also vulgar fractions
    and various other linguistic characters and ideographs that have an innate numeric value.
    These properties are exposed below. They can be useful for determining whether segments
    of text contain numbers or non-numeric data, and can also help in the design of algorithms
    to determine the values of such numbers.
    extension Unicode.Scalar.Properties {

      /// Corresponds to the `Numeric_Type` Unicode property.
      public var numericType: Unicode.NumericType?

      /// Corresponds to the `Numeric_Value` Unicode property.
      public var numericValue: Double?
    }

    extension Unicode {

      public enum NumericType {
        case decimal
        case digit
        case numeric
      }
    }


14/06/2021
<a target="_blank" rel="noopener noreferrer" href="https://lists.isocpp.org/sg16/2018/08/0113.php">https://lists.isocpp.org/sg16/2018/08/0113.php</a>
Feedback from swift team

    <a target="_blank" rel="noopener noreferrer" href="https://lists.isocpp.org/sg16/2018/08/0121.php">https://lists.isocpp.org/sg16/2018/08/0121.php</a>
    Swift strings now sort with NFC (currently UTF-16 code unit order, but likely changed to Unicode scalar value order).
    We didn't find FCC significantly more compelling in practice. Since NFC is far more frequent in the wild
    (why waste space if you don't have to), strings are likely to already be in NFC.
    We have fast-paths to detect on-the-fly normal sections of strings (e.g. all ASCII, all &lt; U+0300, NFC_QC=yes, etc.).
    We lazily normalize portions of string during comparison when needed.
    Q: Swift strings support comparison via normalization. Has use of canonical string equality been a performance issue?
       Or been a source of surprise to programmers?
    A: This was a big performance issue on Linux, where we used to do UCA+DUCET based comparisons.
       We switch to lexicographical order of NFC-normalized UTF-16 code units (future: scalar values),
       and saw a very significant speed up there. The remaining performance work revolves around checking
       and tracking whether a string is known to already be in a normal form, so we can just memcmp.
    Q: I'm curious why this was a larger performance issue for Linux than for (presumably) macOS and/or iOS.
    A: There were two main factors.
       The first is that on Darwin platforms, CFString had an implementation that we used instead of UCA+DUCET which was faster.
       The second is that Darwin platforms are typically up-to-date and have very recent versions of ICU.
       On Linux, we still support Ubuntu LTS 14.04 which has a version of ICU which predates Swift and didn't have any fast-paths for ASCII or mostly-ASCII text.
       Switching to our own implementation based on NFC gave us many X improvement over CFString, which in turn was many X faster than UCA+DUCET (especially on older versions of ICU).
    Q: How firmly is the Swift string implementation tied to ICU?
       If the C++ standard library were to add suitable Unicode support, what would motivate reimplementing Swift strings on top of it?
    A: Swift's tie to ICU is less firm than it used to be
       If the C++ standard library provided these operations, sufficiently up-to-date with Unicode version and comparable or better to ICU in performance,
       we would be willing to switch. A big pain in interacting with ICU is their limited support for UTF-8.
       Some users who would like to use a lighter-weight Swift and are unhappy at having to link against ICU, as it's fairly large, and it can complicate security audits.


<hr><h2 id="Zig_lang__Ziglyph">Zig lang, Ziglyph</h2><hr>
04/07/2021
<a target="_blank" rel="noopener noreferrer" href="https://github.com/jecolon/ziglyph">https://github.com/jecolon/ziglyph</a>
Unicode text processing for the Zig programming language.

<a target="_blank" rel="noopener noreferrer" href="https://devlog.hexops.com/2021/unicode-data-file-compression/">https://devlog.hexops.com/2021/unicode-data-file-compression/</a>
achieving 40-70% reduction over gzip alone

<a target="_blank" rel="noopener noreferrer" href="https://github.com/jecolon/ziglyph/issues/3">https://github.com/jecolon/ziglyph/issues/3</a>
More size-optimal grapheme cluster sorting
</pre>
</body>
</html>
